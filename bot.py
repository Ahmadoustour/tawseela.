import os
import hashlib
import time
import schedule
import requests
import pandas as pd
import numpy as np
import json
import joblib
import threading
import shutil
import telegram.error
import binance.exceptions
import logging
import sys
import traceback
import platform
import psutil
import holidays
import sklearn
from logging.handlers import RotatingFileHandler
from datetime import datetime, timedelta, time, timezone
from binance.client import Client
from binance.exceptions import BinanceAPIException
from telegram import Bot
from telegram import constants
from telethon.sync import TelegramClient
from dotenv import load_dotenv
from ta.trend import EMAIndicator, ADXIndicator, MACD
from ta.momentum import RSIIndicator
from ta.volatility import BollingerBands
from xgboost import XGBClassifier
from bs4 import BeautifulSoup
from textblob import TextBlob
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from threading import Lock
from sklearn.metrics import accuracy_score, precision_score, recall_score
from concurrent.futures import ThreadPoolExecutor
from telegram.error import NetworkError
from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit
from collections import OrderedDict
from joblib import Memory
import telegram
from packaging import version

if version.parse(telegram.__version__) >= version.parse("20.0"):
    from telegram.constants import ParseMode
else:
    from telegram import ParseMode
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©
load_dotenv()

# Ø§Ù„Ø£ÙØ¶Ù„ Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ù„Ù Ø¨Ø¹Ø¯ Ø§Ù„ÙˆØ§Ø±Ø¯Ø§Øª
class APIError(Exception):
    def __init__(self, message, status_code=None):
        self.status_code = status_code
        super().__init__(message)

class APIConnectionError(Exception):
    def __init__(self, message, original_exception=None):
        self.original = original_exception
        super().__init__(f"{message}: {str(original_exception)}")

class APITimeoutError(APIError):
    """Ù…Ù‡Ù„Ø© Ø·Ù„Ø¨ API"""

class BinanceAPIError(APIError):
    """Ø®Ø·Ø£ Ù…Ù† Binance API"""
    
class InsufficientFundsError(APIError):
    """Ø±ØµÙŠØ¯ ØºÙŠØ± ÙƒØ§ÙÙŠ"""
    
class InvalidResponseError(APIError):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©"""
    
class TradingBot:

    def __init__(self):
        # ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
        self.lock = Lock()
        self.is_running = False
        self.start_time = None
        self.current_positions = {}
        self.symbols = ["ADAUSDT", "XLMUSDT", "ALGOUSDT"]
        self.models = {}
        self.news_sources = ["telegram", "twitter", "coindesk", "cryptopanic", "newsapi"]
        self.rotation_index = 0
        self.last_api_call = {}
        self._model_cache = OrderedDict()
        self._max_cached_models = 3
        self.news_rotation_indices = dict.fromkeys(self.symbols, 0)
        self.news_fetch_interval_hours = 12
        self.last_news_fetch_time = datetime.min
        self.optimal_trading_hours = []
        self._news_cache = {}
        self.memory = Memory(location='./cachedir', verbose=0)  # Ø®Ø§ØµÙŠØ© Ø«Ø§Ø¨ØªØ© Ù„Ù„ÙƒÙ„Ø§Ø³
        self.ROTATION_INDEX_FILE = 'rotation_index.json'
        self.TWEET_FIELDS_KEY = 'tweet.fields'
        self.OBJECTIVE_BINARY = 'binary:logistic'

        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
        self.news_sentiment = {
            symbol: {
                "score": 0,
                "positive": 0,
                "negative": 0,
                "neutral": 0,
                "last_updated": None,
                "source": None
            } for symbol in self.symbols
        }

        self.pro_signals = {symbol: [] for symbol in self.symbols}
        self.trailing_stops = dict.fromkeys(self.symbols, None)
        self.last_peaks = dict.fromkeys(self.symbols, None)
        self.fib_levels = dict.fromkeys(self.symbols, None)
        self.pivot_points = dict.fromkeys(self.symbols, None)

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„
        self.min_profit = 0.4
        self.trailing_percent = 0.1
        self.min_expected_profit = 0.6  

        # ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        self._init_logging()

        # ØªÙ‡ÙŠØ¦Ø© APIs
        try:
            self.client = Client(os.getenv('BINANCE_API_KEY'), os.getenv('BINANCE_SECRET_KEY'))
            self.tg_bot = Bot(token=os.getenv('TELEGRAM_TOKEN'))
        except Exception as e:
            self.logger.critical("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© APIs - Ø§Ù„Ø®Ø·Ø£: %s", str(e), exc_info=True)
            self.send_notification(
                'error',
                f"ğŸ”¥ ÙØ´Ù„ Ø­Ø±Ø¬ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© APIs\n"
                f"ğŸ“› Ø§Ù„ØªÙØ§ØµÙŠÙ„: {str(e)}\n"
                f"â° Ø§Ù„ÙˆÙ‚Øª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )
            self.shutdown_bot(reason=f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© APIs: {str(e)}")
            raise RuntimeError(f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© APIs - ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨ÙˆØª. Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø£ØµÙ„ÙŠ: {str(e)}") from e

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆØ§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        self.load_state()
        self.load_rotation_index()

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„ÙƒÙ„ Ø¹Ù…Ù„Ø© Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø·ÙˆØ§Ø±Ø¦ Ù…ØªÙƒØ§Ù…Ù„
        self.models = {}
        for symbol in self.symbols:
            try:
                # 1. Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
                model = self.load_or_initialize_model(symbol, use_cache=True)
                
                # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                if model is None:
                    raise ValueError("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„ (Ù‚ÙŠÙ…Ø© None)")
                
                # 3. Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
                test_data = pd.DataFrame([[
                    0, 0, 50, 0, 1000000, 0, 0
                ]], columns=[
                    'ema20', 'ema50', 'rsi', 'macd',
                    'volume', 'news_sentiment', 'signal_count'
                ])
                
                prediction = model.predict(test_data)
                if prediction is None or len(prediction) == 0:
                    raise ValueError("ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª")
                
                # 4. Ø¥Ø°Ø§ Ù†Ø¬Ø­Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
                self.models[symbol] = model
                self.logger.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ù„Ù€ %s", symbol)
                
            except Exception as e:
                self.logger.error("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
                
                try:
                    # 5. Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                    backup_model = self._load_backup_model(symbol)
                    if backup_model:
                        self.models[symbol] = backup_model
                        self.logger.warning("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù€ %s", symbol)
                        continue
                        
                    # 6. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ Ø¨Ø³ÙŠØ·
                    self.models[symbol] = self._create_emergency_model()
                    self.logger.critical("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ Ù„Ù€ %s", symbol)
                    
                    self.send_notification(
                           'warning',
                           f"âš ï¸ ØªØ­Ø°ÙŠØ±: ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ Ù„Ù€ {symbol}\nØ§Ù„Ø³Ø¨Ø¨: {str(e)[:150]}"
                     )
                    
                except Exception as emergency_error:
                    self.logger.critical(
                        "ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ Ù„Ù€ %s: %s",
                        symbol, str(emergency_error),
                        exc_info=True
                    )
                    self.shutdown_bot(reason=f"ÙØ´Ù„ Ø­Ø±Ø¬ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(emergency_error)}")
                    raise RuntimeError(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¨Ø¯ÙˆÙ† Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}") from emergency_error

    def initialize_fallback_model(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ø£Ø³Ø§Ø³ÙŠ ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„"""
        try:
            model = Pipeline([
                ('scaler', StandardScaler()),
                ('xgb', XGBClassifier(
                    objective=self.OBJECTIVE_BINARY,
                    learning_rate=0.05,
                    max_depth=3,
                    n_estimators=100,
                    random_state=42
                ))
            ], memory=self.memory)

            rng = np.random.default_rng(42)  # ØªØ¹ÙŠÙŠÙ† seed Ø«Ø§Ø¨Øª
            dummy_x = pd.DataFrame(
                rng.random((10, 7)),
                columns=[
                    'ema20', 'ema50', 'rsi', 'macd',
                    'volume', 'news_sentiment', 'signal_count'
                ]
            )
            dummy_y = rng.integers(0, 2, size=10)

            model.fit(dummy_x, dummy_y)

            return model

        except Exception as e:
            print(f"ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„: {e}")
            raise RuntimeError("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„") from e

    def _init_logging(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¢Ù…Ù† Ù…Ø¹ ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¹Ø§Ø±Ø¶ ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª"""
        try:
            # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù„ÙˆØ¬Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            logs_dir = 'logs'
            os.makedirs(logs_dir, exist_ok=True)

            # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… ÙØ±ÙŠØ¯ Ù„Ù„ logger Ù…Ø¹ ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¹Ø§Ø±Ø¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            logger_name = f'trading_bot_{timestamp}'
            
            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø¨Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… (Ø­Ù…Ø§ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©)
            log_file = f'{logs_dir}/bot_{datetime.now().strftime("%Y%m%d")}.log'
            counter = 1
            while os.path.exists(log_file):
                log_file = f'{logs_dir}/bot_{datetime.now().strftime("%Y%m%d")}_{counter}.log'
                counter += 1

            # 4. Ø¥Ù†Ø´Ø§Ø¡ logger Ø¬Ø¯ÙŠØ¯
            self.logger = logging.getLogger(logger_name)
            self.logger.setLevel(logging.DEBUG)

            # 5. Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ø§Ù„ handlers
            if self.logger.hasHandlers():
                self.logger.handlers.clear()

            # 6. Ø¥Ù†Ø´Ø§Ø¡ formatter Ù…ØªÙ‚Ø¯Ù…
            formatter = logging.Formatter(
                '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s | Line:%(lineno)d',
                datefmt='%Y-%m-%d %H:%M:%S'
            )

            # 7. Ø¥Ù†Ø´Ø§Ø¡ file handler Ù…Ø¹ ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª
            file_handler = RotatingFileHandler(
                log_file,
                maxBytes=5*1024*1024,  # 5MB
                backupCount=3,
                encoding='utf-8'
            )
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)

            # 8. Ø¥Ù†Ø´Ø§Ø¡ console handler Ù„Ù„Ø·ÙˆØ§Ø±Ø¦
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)

            # 9. ØªØ³Ø¬ÙŠÙ„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
            self.logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­")

        except Exception as e:
          #Ù†Ø¸Ø§Ù… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø¹Ù†Ø¯ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„
            try:
                # Ø£. ØªÙ‡ÙŠØ¦Ø© Ø£Ø³Ø§Ø³ÙŠØ§Øª logging
                logging.basicConfig(
                    level=logging.DEBUG,
                    format='%(asctime)s - EMERGENCY - %(message)s',
                    handlers=[
                        logging.StreamHandler(),  # Ø¥Ø®Ø±Ø§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„ÙƒÙˆÙ†Ø³ÙˆÙ„
                        logging.FileHandler('emergency.log')  # Ù…Ù„Ù Ø·ÙˆØ§Ø±Ø¦ Ù…Ù†ÙØµÙ„
                    ]
                )

                # Ø¨. Ø¥Ù†Ø´Ø§Ø¡ logger Ø§Ù„Ø·ÙˆØ§Ø±Ø¦
                emergency_logger = logging.getLogger('EMERGENCY_LOGGER')
                emergency_logger.setLevel(logging.DEBUG)

                # Ø¬. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø®Ø·Ø£
                emergency_logger.critical("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ | Ø§Ù„Ø®Ø·Ø£: %s", str(e), exc_info=True)
                # Ø¯. ØªØ¹ÙŠÙŠÙ† logger Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ù„Ù„Ù†Ø¸Ø§Ù…
                self.logger = emergency_logger

            except Exception as nested_ex:
                # Ø£Ø¨Ø³Ø· Ø­Ù„ ÙƒØ­Ù…Ø§ÙŠØ© Ø£Ø®ÙŠØ±Ø©
                with open('crash_report.log', 'a', encoding='utf-8') as f:
                    f.write(f"[{datetime.now()}] SYSTEM COLLAPSE: {str(e)}\n")
                    f.write(f"[{datetime.now()}] EMERGENCY FAILURE: {str(nested_ex)}\n")
        
    def _clean_model_cache(self):
        while len(self._model_cache) > self._max_cached_models:
            symbol, _ = self._model_cache.popitem(last=False)
            print(f"ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø©: {symbol} (Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¢Ù†: {len(self._model_cache)})")
            
    def add_model(self, symbol, model):
        self._model_cache[symbol] = model
        self._clean_model_cache()

    def _safe_load_model(self, path):
        """Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø¶Ù…Ø§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"""
        try:
            # 1. ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
            if not os.path.exists(path):
                raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {path}")

            # 2. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…
            if os.path.getsize(path) == 0:
                raise ValueError("Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙØ§Ø±Øº")

            # 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            with open(path, 'rb') as f:
                model = joblib.load(f)

            # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            required_methods = ['predict', 'fit']
            for method in required_methods:
                if not hasattr(model, method):
                    raise AttributeError(f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙØªÙ‚Ø¯ Ø¥Ù„Ù‰: {method}")

            # 5. Ø¥ØµØ¯Ø§Ø± sklearn
            if hasattr(model, '__sklearn_version__'):
                current_version = sklearn.__version__
                model_version = model.__sklearn_version__
                if model_version != current_version:
                    self.logger.warning("âš ï¸ Ø¥ØµØ¯Ø§Ø± sklearn ØºÙŠØ± Ù…ØªØ·Ø§Ø¨Ù‚ (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: %sØŒ Ø§Ù„Ø­Ø§Ù„ÙŠ: %s)", model_version, current_version)

            return model

        except Exception as e:
            # 6. Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù
            try:
                corrupt_path = f"{path}.corrupt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                shutil.move(path, corrupt_path)
                self.logger.error("ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ§Ù„Ù Ø¥Ù„Ù‰: %s", corrupt_path)
            except Exception as move_error:
                self.logger.error("ÙØ´Ù„ Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù: %s", str(move_error))

            self.send_notification(
                'error',
                f"âŒ Ù†Ù…ÙˆØ°Ø¬ ØªØ§Ù„Ù\n"
                f"ğŸ“‚ {os.path.basename(path)}\n"
                f"ğŸ“› {type(e).__name__}: {str(e)[:100]}"
            )
            return None

    def _log_reset(self, reason):
        """ØªØ³Ø¬ÙŠÙ„ ØªÙØ§ØµÙŠÙ„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ†"""
        msg = f"ØªÙ… Ø¶Ø¨Ø· Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±. Ø§Ù„Ø³Ø¨Ø¨: {reason} | Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {self.news_sources}"
        self.logger.warning("%s", msg)
        self.send_notification('config_update', msg)

    def collect_market_data(self, symbol):  # <-- Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„Ø©
        """
        Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø¹Ø±ÙŠØ© Ù„Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ
        
        Parameters:
            symbol (str): Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„ 'ADAUSDT').
        
        Returns:
            DataFrame: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ø¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø£Ùˆ None Ø¥Ø°Ø§ ÙØ´Ù„.
        """
        try:
            df = self.get_historical_data(symbol)
            if df is None or df.empty:
                raise ValueError("âš ï¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©")
            
            df = self.calculate_technical_indicators(df)
            return df

        except requests.exceptions.RequestException as e:
            self.send_notification('connection', f'ğŸŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø´Ø¨ÙƒØ©: {e}')
            return None

        except Exception as e:
            self.send_notification('error', f'âŒ ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {type(e).__name__}: {e}')
            return None

    def fetch_signals_for_symbol(self, symbol):
        """
        Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù„Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø© Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©

        Args:
            symbol (str): Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„ 'ADAUSDT')

        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ Ø¥Ø´Ø§Ø±Ø©
        """
        signals = []

        try:
            # 1. Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªÙˆÙŠØªØ±
            twitter_signals = self._fetch_twitter_signals(symbol)
            signals.extend(twitter_signals)

            # 2. Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
            telegram_signals = self._fetch_telegram_signals(symbol)
            signals.extend(telegram_signals)

            # 3. Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰
            other_signals = self._fetch_other_sources(symbol)
            signals.extend(other_signals)

        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
            self.send_notification('error', f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª {symbol}")

        return signals

    def get_latest_crypto_news(self, symbol, hours=48):
        """
        Ø¬Ù…Ø¹ Ø£Ø­Ø¯Ø« Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø© Ø®Ù„Ø§Ù„ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù„Ø±Ù…Ø² Ù…Ø¹ÙŠÙ†
        """
        news_items = []
        cutoff_time = datetime.now() - timedelta(hours=hours)

        # 1. Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ØªÙˆÙŠØªØ±
        try:
            twitter_news = self._fetch_twitter_news(hours)
            if twitter_news:
                news_items.extend([
                    item for item in twitter_news 
                    if datetime.fromisoformat(item['time']) > cutoff_time
                ])
        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± ØªÙˆÙŠØªØ±: %s", str(e))

        # 2. Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ÙƒÙˆÙŠÙ† Ø¯ÙŠØ³Ùƒ
        try:
            coindesk_news = self.scrape_coindesk_news(symbol)
            if coindesk_news:
                news_items.extend([
                    item for item in coindesk_news 
                    if datetime.fromisoformat(item['time']) > cutoff_time
                ])
        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± ÙƒÙˆÙŠÙ† Ø¯ÙŠØ³Ùƒ: %s", str(e))

        # 3. Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ÙƒØ±ÙŠØ¨ØªÙˆ Ø¨Ø§Ù†ÙŠÙƒ (ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù†ÙˆÙŠØ§Øª ÙÙ‚Ø·ØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø± Ù…ÙØµÙ„Ø©)
        try:
            self.scrape_cryptopanic_news(symbol)  # Ù„Ø§ ØªØ±Ø¬Ø¹ Ø£Ø®Ø¨Ø§Ø±
        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± ÙƒØ±ÙŠØ¨ØªÙˆ Ø¨Ø§Ù†ÙŠÙƒ: %s", str(e))

        # 4. Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        try:
            telegram_news = self.scrape_telegram_news()
            if telegram_news:
                news_items.extend([
                    item for item in telegram_news 
                    if datetime.fromisoformat(item['time']) > cutoff_time
                ])
        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± ØªÙ„ÙŠØ¬Ø±Ø§Ù…: %s", str(e))

        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø­Ø³Ø¨ Ø§Ù„Ø£Ø­Ø¯Ø«
        news_items.sort(key=lambda x: datetime.fromisoformat(x['time']), reverse=True)

        return news_items[:50]  # Ø¥Ø±Ø¬Ø§Ø¹ Ø¢Ø®Ø± 50 Ø®Ø¨Ø± ÙÙ‚Ø·

    def _fetch_twitter_signals(self, symbol):
        """Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† Ø¯Ø§Ù„Ø© Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªÙˆÙŠØªØ± Ø¨ØªØ­Ù„ÙŠÙ„ Ù„ØºÙˆÙŠ Ù…ØªÙ‚Ø¯Ù…"""
        signals = []
        coin_name = symbol[:-4]  # Ø¥Ø²Ø§Ù„Ø© USDT
        cutoff_time = datetime.now() - timedelta(hours=48)
        trusted_sources = ['CryptoMichNL', 'Ali_Charts', 'rektcapital', 'CryptoTony__', 'TheCryptoDog']
        
        for username in trusted_sources:
            try:
                tweets = self._get_user_tweets(username)
                for tweet in tweets:
                    try:
                        tweet_time = self._safe_parse_date(tweet.get('created_at', ''))
                        if tweet_time is None or tweet_time < cutoff_time:
                            continue
                            
                        tweet_text = tweet.get('text', '').lower()
                        
                        # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø°ÙƒØ± Ø§Ù„Ø¹Ù…Ù„Ø©
                        if coin_name.lower() not in tweet_text:
                            continue
                            
                        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
                        sentiment = self._advanced_sentiment_analysis(tweet_text)
                        
                        # 3. Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø¶Ù…Ù†ÙŠØ©
                        signal_type = self._detect_signal_type(tweet_text)
                        
                        if signal_type != 'neutral':
                            signals.append({
                                'source': 'Twitter',
                                'author': username,
                                'text': tweet.get('text', '')[:200],
                                'time': tweet_time.isoformat(),
                                'sentiment': sentiment,
                                'signal_type': signal_type,
                                'confidence': self._calculate_confidence(tweet_text)
                            })
                    except Exception as tweet_error:
                        self.logger.warning("Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØºØ±ÙŠØ¯Ø© Ù…Ù† %s: %s", username, str(tweet_error))
                        continue
                        
            except Exception as e:
                self.logger.warning("ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØºØ±ÙŠØ¯Ø§Øª %s: %s", username, str(e))
                continue

        return signals

    @staticmethod
    def _advanced_sentiment_analysis(text):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TextBlob Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª"""
        analysis = TextBlob(text)
        
        # ØªØ­Ø³ÙŠÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø§Ù„ÙŠ
        financial_words = {
            'bullish': 0.8,
            'bearish': -0.8,
            'pump': -0.5,
            'dump': -0.7,
            'moon': 0.9,
            'rocket': 0.7,
            'crash': -0.9,
            'rally': 0.6
        }
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©
        for word, weight in financial_words.items():
            if word in text:
                # Ù†Ø¹Ø¯Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¨Ø­ÙŠØ« ØªØ¨Ù‚Ù‰ Ø¨ÙŠÙ† -1 Ùˆ1
                analysis.sentiment = analysis.sentiment._replace(
                    polarity=min(1.0, max(-1.0, analysis.sentiment.polarity + weight * 0.3))
                )
        
        return round(analysis.sentiment.polarity, 2)

    @staticmethod
    def _detect_signal_type(text):
        """Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ§Ù‚ÙŠ"""
        text = text.lower()
        
        # Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ø§Ù„Ø©
        buy_signals = ['buy', 'long', 'bullish', 'accumulate', 'entry', 'moon', 'rocket']
        sell_signals = ['sell', 'short', 'bearish', 'exit', 'dump', 'crash']
        caution_signals = ['warning', 'caution', 'careful', 'volatile']
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
        buy_count = sum(text.count(word) for word in buy_signals)
        sell_count = sum(text.count(word) for word in sell_signals)
        caution_count = sum(text.count(word) for word in caution_signals)
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
        if buy_count > sell_count and buy_count > caution_count:
            return 'buy'
        elif sell_count > buy_count and sell_count > caution_count:
            return 'sell'
        elif caution_count > max(buy_count, sell_count):
            return 'caution'
        else:
            return 'neutral'

    @staticmethod
    def _calculate_confidence(text):
        """Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø¹ÙˆØ§Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯Ø©"""
        factors = []

        # 1. Ø·ÙˆÙ„ Ø§Ù„ØªØºØ±ÙŠØ¯Ø©
        factors.append(min(1.0, len(text) / 100))

        # 2. Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¯Ø§Ù„Ø©
        keywords = ['target', 'stop', 'resistance', 'support', 'breakout']
        factors.append(min(1.0, sum(text.count(kw) for kw in keywords) / 3))

        # 3. Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… (Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù‚ÙˆÙŠØ©)
        strong_punct = ['!', 'ğŸš€', 'ğŸ”¥', 'ğŸ“ˆ', 'ğŸ“‰']
        factors.append(min(1.0, sum(text.count(p) for p in strong_punct) / 2))

        # Ù…ØªÙˆØ³Ø· Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø«Ù‚Ø©
        return round(sum(factors) / len(factors), 2)

    def _safe_parse_date(self, date_str):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ø¯Ø¹Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"""
        if not date_str:
            return None
            
        formats_to_try = [
            '%Y-%m-%dT%H:%M:%S.%fZ',  # Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£ØµÙ„ÙŠ
            '%Y-%m-%dT%H:%M:%SZ',     # ØªÙ†Ø³ÙŠÙ‚ Ø¨Ø¯ÙˆÙ† Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
            '%a %b %d %H:%M:%S %z %Y' # ØªÙ†Ø³ÙŠÙ‚ Ø¢Ø®Ø± Ø´Ø§Ø¦Ø¹ ÙÙŠ ØªÙˆÙŠØªØ±
        ]
        
        for fmt in formats_to_try:
            try:
                return datetime.strptime(date_str, fmt)
            except ValueError:
                continue
                
        self.logger.warning("ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®: %s - Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ†Ø³ÙŠÙ‚ Ù…Ø·Ø§Ø¨Ù‚", date_str)
        return None

    def _fetch_twitter_news(self, hours=48):  # Ø¬Ø¹Ù„ hours=48 Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§
        query = "crypto OR cryptocurrency OR bitcoin OR ethereum -filter:retweets"
        tweets = self._search_twitter(query, count=50)
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        news = []
        for tweet in tweets:
            tweet_time = datetime.strptime(tweet['created_at'], '%Y-%m-%dT%H:%M:%S.%fZ')
            if tweet_time > cutoff_time:
                news.append({
                    'source': 'Twitter',
                    'author': tweet['user']['screen_name'],
                    'text': tweet['text'],
                    'time': tweet_time.isoformat(),
                    'sentiment': TextBlob(tweet['text']).sentiment.polarity
                })
        
        return news

    def get_all_twitter_data(self, symbol=None, hours=48):
        all_data = []
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª (Ø¥Ø°Ø§ ÙˆÙÙØ± Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø©)
        if symbol:
            all_data.extend(self._fetch_twitter_signals(symbol))
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ø§Ù…Ø©
        all_data.extend(self._fetch_twitter_news(hours))
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„ØªØºØ±ÙŠØ¯Ø©
        unique_data = {item['text']: item for item in all_data}.values()
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ‚Øª (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
        return sorted(unique_data, key=lambda x: x['time'], reverse=True)

    @staticmethod
    def _get_twitter_api_v2():
        """ØªÙ‡ÙŠØ¦Ø© Ø§ØªØµØ§Ù„ Twitter API v2 Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Bearer Token"""
        headers = {
            "Authorization": f"Bearer {os.getenv('TWITTER_BEARER_TOKEN')}",
            "User-Agent": "v2UserLookupPython"
        }
        return headers

    def _get_user_tweets(self, username, count=15):
        """
        Ø¬Ù„Ø¨ ØªØºØ±ÙŠØ¯Ø§Øª Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Twitter API v2
        
        Args:
            username (str): Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ ØªÙˆÙŠØªØ±
            count (int): Ø¹Ø¯Ø¯ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ 15)
        
        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© ØªØºØ±ÙŠØ¯Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        """
        try:
            headers = self._get_twitter_api_v2()
            if not headers:
                return []

            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ID Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            user_url = f"https://api.twitter.com/2/users/by/username/{username}"
            user_response = requests.get(user_url, headers=headers)
            user_data = user_response.json()

            if 'data' not in user_data:
                return []

            user_id = user_data['data']['id']

            # Ø¬Ù„Ø¨ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª
            tweets_url = f"https://api.twitter.com/2/users/{user_id}/tweets"
            params = {
                'max_results': count,
                'exclude': 'replies,retweets',
                self.TWEET_FIELDS_KEY: 'created_at,text'
            }

            tweets_response = requests.get(tweets_url, headers=headers, params=params)
            tweets_data = tweets_response.json()

            return [{
                'text': tweet['text'],
                'created_at': tweet['created_at'],
                'user': {
                    'username': username,
                    'id': user_id
                }
            } for tweet in tweets_data.get('data', [])]

        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ ØªØºØ±ÙŠØ¯Ø§Øª %s: %s", username, str(e))
            return []

    def _fetch_telegram_signals(self, symbol):
        """Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ù…Ø®ØµØµØ©"""
        signals = []
        coin_name = symbol[:-4]  # Ø¥Ø²Ø§Ù„Ø© USDT

        try:
            channels = [
                'CryptoSignalsIO',
                'BinanceSignalsOfficial',
                'UniversalCryptoSignals'
            ]

            api_id = int(os.getenv('TG_API_ID'))
            api_hash = os.getenv('TG_API_HASH')

            with TelegramClient('session_name', api_id, api_hash) as client:
                for channel in channels:
                    try:
                        messages = client.get_messages(channel, limit=20)

                        for msg in messages:
                            if not msg.text:
                                continue

                            if (coin_name.lower() in msg.text.lower() and
                                any(word in msg.text.lower()
                                    for word in ['buy', 'long', 'bullish'])):

                                sentiment = TextBlob(msg.text).sentiment.polarity

                                signals.append({
                                    'source': 'Telegram',
                                    'channel': channel,
                                    'text': msg.text[:200],
                                    'time': msg.date.isoformat(),
                                    'sentiment': round(sentiment, 2)
                                })

                    except Exception as e:
                        self.logger.warning("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø±Ø³Ø§Ø¦Ù„ %s: %s", channel, str(e))
                        continue

        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…: %s", str(e), exc_info=True)
            raise

        return signals

    @staticmethod
    def _fetch_other_sources(symbol):
        """Ø¬Ù„Ø¨ Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰ (Ù…Ø«Ù„ Ù…Ù†ØªØ¯ÙŠØ§ØªØŒ Ù…ÙˆØ§Ù‚Ø¹ Ù…ØªØ®ØµØµØ©)"""
        signals = []

        # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰ Ù‡Ù†Ø§
        # Ù…Ø«Ù„: TradingView, CoinMarketCap, etc.

        return signals

    def start_scheduler(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© Ø¨Ø¯ÙˆÙ† ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø¨ÙˆØ¹ÙŠ"""
        if self.is_running:
            return  # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ¹Ù…Ù„ Ù„Ø§ Ù†Ø¹ÙŠØ¯ ØªØ´ØºÙŠÙ„Ù‡Ø§

        self.is_running = True

        def scheduler_loop():
            while self.is_running:  # Ø§Ù„Ø´Ø±Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯
                try:
                    schedule.run_pending()
                    time.sleep(1)
                except Exception as e:
                    self.logger.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©: %s", e)
                    time.sleep(5)

        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø«Ø±ÙŠØ¯
        threading.Thread(
            target=scheduler_loop,
            daemon=True
        ).start()

    def _run_weekly_optimization(self):
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        self.logger.info("Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ")
        for symbol in self.symbols:
            try:
                self.optimize_entry_conditions(symbol)
            except Exception as sym_error:
                self.logger.error("ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† %s: %s", symbol, str(sym_error), exc_info=True)
        self.logger.info("Ø§ÙƒØªÙ…Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ")
    
    def analyze_news_sentiment(self, symbol=None):
        """
        ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ø¹ Ø¶Ù…Ø§Ù†Ø§Øª Ø¹Ø¯Ù… Ø§Ù„ÙØ´Ù„
        Args:
            symbol: Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø®Ø§ØµÙ‹Ø§ Ø¨Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø©
        Returns:
            float: Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨ÙŠÙ† -1 (Ø³Ù„Ø¨ÙŠØ©) Ùˆ +1 (Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©)
        """
        total_score = 0.0
        count = 0

        try:
            # 1. Ø£Ø®Ø¨Ø§Ø± Ù…Ù† NewsAPI
            if 'newsapi' in self.news_sources:
                try:
                    url = f"https://newsapi.org/v2/everything?q={'Crypto' if not symbol else symbol[:-4]}&apiKey={os.getenv('NEWSAPI_KEY')}"
                    response = requests.get(url, timeout=10)
                    articles = response.json().get('articles', [])

                    for article in articles[:5]:
                        content = f"{article.get('title', '')}. {article.get('description', '')}"
                        if content.strip():
                            sentiment = TextBlob(content).sentiment.polarity
                            total_score += sentiment
                            count += 1
                except Exception as e:
                    self.logger.error("NewsAPI Error: %s", str(e), exc_info=True)

            # 2. Ø£Ø®Ø¨Ø§Ø± Ù…Ù† CryptoPanic
            if 'cryptopanic' in self.news_sources:
                try:
                    coin_symbol = symbol[:-4] if symbol else 'BTC'
                    url = f"https://cryptopanic.com/api/v1/posts/?auth_token={os.getenv('CRYPTO_PANIC_KEY')}&currencies={coin_symbol}"
                    response = requests.get(url, timeout=10)
                    posts = response.json().get('results', [])

                    for post in posts[:5]:
                        content = f"{post.get('title', '')}. {post.get('body', '')}"
                        if content.strip():
                            sentiment = TextBlob(content).sentiment.polarity
                            total_score += sentiment
                            count += 1
                except Exception as e:
                    self.logger.error("CryptoPanic Error: %s", str(e), exc_info=True)

            # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            final_score = total_score / max(1, count)

            # 4. ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø±Ù…Ø²
            if symbol:
                self.news_sentiment[symbol] = {
                    'score': round(final_score, 4),
                    'positive': sum(1 for _ in range(count) if _ > 0.1),
                    'negative': sum(1 for _ in range(count) if _ < -0.1),
                    'neutral': sum(1 for _ in range(count) if -0.1 <= _ <= 0.1),
                    'last_updated': datetime.now(timezone.utc).isoformat(),
                    'source': 'combined'
                }

            return round(final_score, 4)

        except Exception as e:
            self.logger.critical("Total Sentiment Analysis Failure: %s", str(e), exc_info=True)
            return 0.0

    def scrape_cryptopanic_news(self, symbol, cache_hours=4):
        """
        Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ù†ØªØ§Ø¦Ø¬
        """
        cache_key = f"cryptopanic_{symbol}"
        cached_data = self._get_cached_news(cache_key, cache_hours)
        
        if cached_data:
            self.news_sentiment[symbol] = cached_data
            return cached_data  # Ø£Ø¶ÙØª return Ù‡Ù†Ø§ Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø¨Ø£Ø©
            
        try:
            coin_symbol = symbol[:-4].upper()
            trusted_sources = "coindesk,cointelegraph,decrypt"  # Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø© (ÙƒÙ…Ø§ ÙŠØ¯Ø±Ø¬Ù‡Ø§ CryptoPanic)
            url = f"https://cryptopanic.com/api/v1/posts/?auth_token={os.getenv('CRYPTO_PANIC_KEY')}&currencies={coin_symbol}&sources={trusted_sources}&kind=news"
            
            params = {
                'auth_token': os.getenv('CRYPTO_PANIC_KEY'),
                'currencies': coin_symbol,
                'public': 'true',
                'kind': 'news'
            }
            
            response = requests.get(url, params=params, timeout=15)
            data = response.json()
            
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = [executor.submit(self._analyze_cryptopanic_post, post) for post in data.get('results', [])[:5]]
                results = [f.result() for f in futures if f.result() is not None]
            
            if not results:
                return []  # Ø£Ø±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© Ø¨Ø¯Ù„ None
                
            avg_score = sum(r['sentiment'] for r in results) / len(results)
            positive = sum(1 for r in results if r['sentiment'] > 0.1)
            negative = sum(1 for r in results if r['sentiment'] < -0.1)
            neutral = len(results) - positive - negative
            
            sentiment_data = {
                "score": avg_score,
                "positive": positive,
                "negative": negative,
                "neutral": neutral,
                "last_updated": datetime.now(timezone.utc).isoformat(),
                "source": "cryptopanic"
            }
            
            self.news_sentiment[symbol] = sentiment_data
            self._cache_news(cache_key, sentiment_data)
            
            return results  # Ø£Ø¶ÙØª return Ù‡Ù†Ø§ Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            
        except Exception as e:
            self.send_notification('error', f'CryptoPanic Error: {str(e)}')
            return []  # Ø£Ø±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£

    @staticmethod
    def _analyze_cryptopanic_post(post):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù‚Ø§Ù„Ø© ÙØ±Ø¯ÙŠØ© Ù…Ù† CryptoPanic"""
        try:
            title = post.get('title', '')
            body = post.get('body', '')
            
            if not title and not body:
                return None
                
            sentiment = TextBlob(f"{title}. {body}").sentiment.polarity
            return {
                'title': title,
                'sentiment': sentiment
            }
        except Exception:
            return None

    def scrape_newsapi_news(self, symbol):
        try:
            coin_name = symbol[:-4]  # Ø¥Ø²Ø§Ù„Ø© USDT
            trusted_sources = "cointelegraph.com,decrypt.co,coindesk.com"  # Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©
            url = f"https://newsapi.org/v2/everything?q={coin_name}&domains={trusted_sources}&apiKey={os.getenv('NEWSAPI_KEY')}"
            response = requests.get(url)
            articles = response.json().get('articles', [])
            
            total_score = 0
            analyzed_articles = 0
            sentiments = []

            for article in articles[:5]:  # ØªØ­Ù„ÙŠÙ„ 5 Ù…Ù‚Ø§Ù„Ø§Øª ÙÙ‚Ø·
                title = article.get('title', '')
                content = article.get('description', '') or article.get('content', '')
                
                if not content:
                    continue
                    
                sentiment = TextBlob(f"{title}. {content}").sentiment.polarity
                sentiments.append(sentiment)
                total_score += sentiment
                analyzed_articles += 1
            
            if analyzed_articles > 0:
                avg_score = total_score / analyzed_articles
                positive = sum(1 for s in sentiments if s > 0.1)
                negative = sum(1 for s in sentiments if s < -0.1)
                neutral = analyzed_articles - positive - negative

                self.news_sentiment[symbol] = {
                    "score": avg_score,
                    "positive": positive,
                    "negative": negative,
                    "neutral": neutral,
                    "last_updated": datetime.now(timezone.utc).isoformat(),
                    "source": "newsapi"
                }
                
        except Exception as e:
            self.send_notification('error', f'âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ NewsAPI: {e}')

    def scrape_coindesk_news(self, symbol, max_articles=5, cache_hours=6):
        """
        Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ©
        """
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø£ÙˆÙ„Ø§Ù‹
            cache_key = f"coindesk_{symbol}"
            cached_data = self._get_cached_news(cache_key, cache_hours)
            
            if cached_data:
                self.news_sentiment[symbol] = cached_data
                return []  # â† Ø±Ø¬ÙˆØ¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ ÙƒØ§Ø´ ÙÙ‚Ø·

            coin_name = symbol[:-4]
            coin_mapping = {
                "ADA": "cardano",
                "XLM": "stellar",
                "ALGO": "algorand",
            }
            
            search_term = coin_mapping.get(coin_name, coin_name.lower())
            trusted_authors = ['omkar-godbole', 'jessica-aznar', 'sam-reynolds']  # ÙƒØªÙ‘Ø§Ø¨ CoinDesk Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠÙ†
            url = f"https://www.coindesk.com/search?s={search_term}&author={','.join(trusted_authors)}"
            
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.find_all('div', class_='article-cardstyles__StyledWrapper-q1x8lc-0')[:max_articles]
            
            if not articles:
                return []  # â† Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§ØªØŒ Ø±Ø¬Ù‘Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = [executor.submit(self._process_coindesk_article, article) for article in articles]
                results = [f.result() for f in futures if f.result() is not None]
            
            if not results:
                return []  # â† Ù„Ø§ Ù†ØªØ§Ø¦Ø¬ Ù…ÙÙŠØ¯Ø©ØŒ Ø±Ø¬Ù‘Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©

            total_score = sum(r['sentiment'] for r in results)
            avg_score = total_score / len(results)
            
            sentiment_data = {
                "score": avg_score,
                "positive": sum(1 for r in results if r['sentiment'] > 0.1),
                "negative": sum(1 for r in results if r['sentiment'] < -0.1),
                "neutral": sum(1 for r in results if -0.1 <= r['sentiment'] <= 0.1),
                "last_updated": datetime.now(timezone.utc).isoformat(),
                "source": "coindesk"
            }
            
            self.news_sentiment[symbol] = sentiment_data
            self._cache_news(cache_key, sentiment_data)
            
            return results  # â† Ø£Ù‡Ù… Ø´ÙŠØ¡: Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬

        except Exception as e:
            self.send_notification('error', f'Coindesk Error: {str(e)}')
            return []  # â† Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£ Ø±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ©

    @staticmethod
    def _process_coindesk_article(article):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù‚Ø§Ù„Ø© ÙØ±Ø¯ÙŠØ© Ù…Ù† Coindesk"""
        try:
            title = article.find('h6').text.strip()
            link = article.find('a')['href']
            
            if not link.startswith('http'):
                link = f"https://www.coindesk.com{link}"
                
            # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ù…Ù‡Ù„Ø© Ù‚ØµÙŠØ±Ø©
            article_response = requests.get(link, timeout=8)
            article_soup = BeautifulSoup(article_response.text, 'html.parser')
            
            content_div = article_soup.find('div', class_='at-content-wrapper')
            if not content_div:
                return None
                
            content = ' '.join(p.text for p in content_div.find_all('p'))
            sentiment = TextBlob(f"{title}. {content}").sentiment.polarity
            
            return {
                'title': title,
                'link': link,
                'sentiment': sentiment
            }
            
        except Exception:
            return None

    def _get_cached_news(self, key, max_hours):
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ù…Ø¤Ù‚ØªÙ‹Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø­Ø¯ÙŠØ«Ø©"""
        cached = self._news_cache.get(key)
        if cached:
            last_updated = datetime.fromisoformat(cached['last_updated'])
            if (datetime.now(timezone.utc) - last_updated) < timedelta(hours=max_hours):
                return cached
        return None

    def _cache_news(self, key, data):
        """ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¤Ù‚ØªÙ‹Ø§"""
        self._news_cache[key] = data

    def scrape_twitter_news(self, symbol=None):
        """
        Ø¬Ù…Ø¹ Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ØªÙˆÙŠØªØ± Ù…Ø¹ Ø¶Ù…Ø§Ù†Ø§Øª Ø¹Ø¯Ù… Ø§Ù„ÙØ´Ù„
        
        Args:
            symbol (str|None): Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„ ADAUSDT) Ø£Ùˆ None Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…
        
        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        """
        try:
            headers = {
                "Authorization": f"Bearer {os.getenv('TWITTER_BEARER_TOKEN')}",
                "User-Agent": "v2TweetLookupPython"
            }

            query = f"#{symbol[:-4]} crypto" if symbol else "crypto news"
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
            if not query.strip():
                self.logger.warning("Ø¨Ø­Ø« ØªÙˆÙŠØªØ± ÙØ§Ø±Øº")
                return []

            search_url = "https://api.twitter.com/2/tweets/search/recent"
            params = {
                'query': query + ' -is:retweet -is:reply',
                'max_results': 15,
                self.TWEET_FIELDS_KEY: 'created_at,text,author_id',
                'expansions': 'author_id',
                'user.fields': 'username'
            }

            response = requests.get(search_url, headers=headers, params=params)
            response.raise_for_status()  # ØªØ£ÙƒÙŠØ¯ Ù†Ø¬Ø§Ø­ Ø§Ù„Ø§ØªØµØ§Ù„

            data = response.json()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            if 'data' not in data or not isinstance(data['data'], list):
                self.logger.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØºØ±ÙŠØ¯Ø§Øª Ù„Ù€ %s", query)
                return []

            # Ø±Ø¨Ø· Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
            users = {}
            if 'includes' in data and 'users' in data['includes']:
                users = {u['id']: u['username'] for u in data['includes']['users']}

            news_items = []
            for tweet in data['data']:
                try:
                    author_id = tweet.get('author_id')
                    news_items.append({
                        'source': 'Twitter',
                        'author': users.get(author_id, f"user_{author_id}"),
                        'text': tweet.get('text', '')[:250],
                        'time': tweet.get('created_at', ''),
                        'sentiment': round(TextBlob(tweet.get('text', '')).sentiment.polarity, 2)
                    })
                except Exception as tweet_error:
                    self.logger.error("Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø©: %s", tweet_error)
                    continue

            return news_items

        except requests.exceptions.RequestException as e:
            self.logger.error("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙˆÙ‚Ø¹ ØªÙˆÙŠØªØ±: %s", str(e))
            return []
        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: %s: %s", type(e).__name__, str(e))
            return []

    def _search_twitter(self, query, count=15):
        """
        Ø¨Ø­Ø« Ø¢Ù…Ù† ÙÙŠ ØªÙˆÙŠØªØ± Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        """
        try:
            headers = self._get_twitter_api_v2()
            if not headers:
                return []

            search_url = "https://api.twitter.com/2/tweets/search/recent"
            params = {
                'query': query,
                'max_results': count,
                self.TWEET_FIELDS_KEY: 'created_at,author_id,text',
                'expansions': 'author_id',
                'user.fields': 'username,name'
            }

            response = requests.get(search_url, headers=headers, params=params)
            response.raise_for_status()

            data = response.json()

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†
            users = {}
            if 'includes' in data and 'users' in data['includes']:
                try:
                    users = {
                        u['id']: {
                            'username': u.get('username', f"user_{u['id']}"),
                            'name': u.get('name', '')
                        }
                        for u in data['includes']['users']
                    }
                except Exception as users_error:
                    self.logger.error("Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: %s", str(users_error))

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†
            tweets = []
            if 'data' in data and isinstance(data['data'], list):
                for tweet in data['data']:
                    try:
                        author_info = users.get(tweet.get('author_id'), {})
                        tweets.append({
                            'text': tweet.get('text', '')[:250],  # ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù†Øµ
                            'created_at': tweet.get('created_at', ''),
                            'user': {
                                'screen_name': author_info.get('username', 'unknown'),
                                'name': author_info.get('name', '')
                            }
                        })
                    except Exception as tweet_error:
                        self.logger.error("Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ±ÙŠØ¯Ø©: %s", str(tweet_error))
                        continue

            return tweets

        except requests.exceptions.RequestException as e:
            self.logger.error("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙˆÙ‚Ø¹ ØªÙˆÙŠØªØ±: %s", str(e))
            return []
        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: %s: %s", type(e).__name__, str(e))
            return []
    
    def scrape_telegram_news(self, symbol=None):
        """
        Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø¹Ù† Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø© Ø£Ùˆ Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…

        Args:
            symbol (str|None): Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© Ø£Ùˆ None Ù„Ù„Ø¹Ø§Ù…

        Returns:
            dict: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        """
        news_items = []
        channels = [
            'CryptocurrencyNews',
            'CoinDesk',
            'CryptoSignals'
        ]
        
        try:
            api_id = int(os.getenv('TG_API_ID'))
            api_hash = os.getenv('TG_API_HASH')
            
            with TelegramClient('session_name', api_id, api_hash) as client:
                for channel in channels:
                    try:
                        # Ø¬Ù„Ø¨ Ø¢Ø®Ø± 20 Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù‚Ù†Ø§Ø©
                        messages = client.get_messages(channel, limit=20)
                        
                        for msg in messages:
                            if not msg.text:
                                continue
                                
                            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù†ØªØ­Ù‚Ù‚ Ù…Ù† Ø°ÙƒØ±Ù‡Ø§
                            if symbol and symbol[:-4].upper() not in msg.text.upper():
                                continue
                                
                            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                            sentiment = TextBlob(msg.text).sentiment.polarity
                            
                            news_items.append({
                                'source': 'Telegram',
                                'channel': channel,
                                'text': msg.text[:250],  # ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù†Øµ
                                'time': msg.date.isoformat(),
                                'sentiment': round(sentiment, 2)
                            })
                            
                    except Exception as e:
                        self.logger.warning("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø±Ø³Ø§Ø¦Ù„ %s: %s", channel, str(e))
                        continue
                        
        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…: %s", str(e), exc_info=True)
            self.send_notification('error', 'âŒ ÙØ´Ù„ Ø¬Ù…Ø¹ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…')
        
        # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø©
        if symbol:
            self.news_sentiment[symbol] = {
                'source': 'telegram',
                'items': news_items,
                'last_updated': datetime.now().isoformat()
            }
        
        return news_items

    def rotate_data_sources(self):
        """
        ØªØ¯ÙˆÙŠØ± Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© ÙˆØ­Ø¯Ø§Ø«Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
            if not hasattr(self, 'news_sources'):
                self.news_sources = ['telegram', 'twitter', 'coindesk', 'cryptopanic', 'newsapi']
                self._log_reset("Ù„Ù… ÙŠØªÙ… ØªØ¹Ø±ÙŠÙ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")

            # 2. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
            current_source = self.news_sources[self.rotation_index]

            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯ÙˆÙŠØ±
            if not self._validate_news_source(current_source):
                self.logger.warning("Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ ØºÙŠØ± ØµØ§Ù„Ø­: %s", current_source)
                self.send_notification('warning', 
                    f"âš ï¸ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù…ØµØ¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ: {current_source}")
                
                # ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…ØµØ¯Ø± ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                self.rotation_index = (self.rotation_index + 1) % len(self.news_sources)
                self.save_rotation_index()
                return

            # 4. ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©
            next_index = (self.rotation_index + 1) % len(self.news_sources)
            validated = False
            attempts = 0

            while attempts < len(self.news_sources):
                next_source = self.news_sources[next_index]
                
                if self._validate_news_source(next_source):
                    validated = True
                    break
                    
                self.logger.warning("ØªÙ… ØªØ®Ø·ÙŠ Ù…ØµØ¯Ø± ØºÙŠØ± ØµØ§Ù„Ø­: %s", next_source)
                next_index = (next_index + 1) % len(self.news_sources)
                attempts += 1

            # 5. Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ØµØ¯Ø± ØµØ§Ù„Ø­ØŒ Ù†Ø¹ÙˆØ¯ Ù„Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£ØµÙ„ÙŠ
            if not validated:
                self.logger.error("ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ØµØ¯Ø± ØµØ§Ù„Ø­ØŒ Ø§Ù„Ø¨Ù‚Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ")
                return

            # 6. Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            self.rotation_index = next_index
            self.save_rotation_index()

            # 7. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            self.logger.info("ØªÙ… Ø§Ù„ØªØ¯ÙˆÙŠØ± Ù…Ù† %s Ø¥Ù„Ù‰ %s", current_source, next_source)
            self.send_notification('update', 
                f"ğŸ”„ ØªÙ… ØªØ¯ÙˆÙŠØ± Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n"
                f"Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯: {next_source}\n"
                f"Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª: {attempts+1}")

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ÙÙŠ ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…ØµØ§Ø¯Ø±: %s", str(e), exc_info=True)
            self.send_notification('error', 
                f"âŒ ÙØ´Ù„ ØªØ¯ÙˆÙŠØ± Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {str(e)[:200]}")

    def _validate_news_source(self, source):
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© ÙˆØ­Ø¯Ø§Ø«Ø© Ù…ØµØ¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
        """
        VALID_SOURCES = {'telegram', 'twitter', 'coindesk', 'cryptopanic', 'newsapi'}
        if source not in VALID_SOURCES:
            return False

        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¯Ø§Ø«Ø© (Ù…Ø«Ø§Ù„ Ù„Ù€ Twitter)
            if source == 'twitter':
                last_tweet = self._get_last_tweet_time()
                if last_tweet and (datetime.now() - last_tweet) > timedelta(hours=6):
                    return False

            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙØ± (Ù…Ø«Ø§Ù„ Ù„Ù€ NewsAPI)
            elif source == 'newsapi':
                try:
                    test_response = requests.get(
                        "https://newsapi.org/v2/top-headlines?" +
                        f"sources=crypto-coins-news&apiKey={os.getenv('NEWSAPI_KEY')}",
                        timeout=10
                    )
                    if test_response.status_code != 200:
                        return False
                except requests.RequestException as e:
                    self.logger.warning("NewsAPI request failed: %s", str(e))
                    return False

            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            sample_data = self._fetch_sample_data(source)
            if not sample_data or not self._is_data_valid(sample_data):
                return False

            return True

        except Exception as e:
            self.logger.warning("ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ØµØ¯Ø± %s: %s", source, str(e))
            return False
            
    @staticmethod
    def _is_data_valid(data):
        """ØªØ­Ù‚Ù‚ Ø¥Ø¶Ø§ÙÙŠ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        required_fields = {
            'telegram': ['text', 'timestamp'],
            'twitter': ['text', 'created_at'],
            'newsapi': ['title', 'publishedAt'],
            'coindesk': ['title', 'time'],
            'cryptopanic': ['title', 'published_at']
        }

        source_type = data.get('source_type')
        if not source_type:
            return False

        for field in required_fields.get(source_type, []):
            if field not in data:
                return False

        return True

    def save_rotation_index(self):
        """
        Ø­ÙØ¸ Ù‚ÙŠÙ…Ø© rotation_index ÙÙŠ Ù…Ù„Ù Ø£Ùˆ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³ÙŠØ·Ø© Ù„ÙŠØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹Ù‡Ø§ Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª.
        """
        try:
            with open(self.ROTATION_INDEX_FILE, 'w') as f:
                json.dump({'rotation_index': self.rotation_index}, f)
        except Exception as e:
            self.send_notification('error', f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ¯ÙˆÙŠØ±: {e}")

    def load_rotation_index(self):
        """
        ØªØ­Ù…ÙŠÙ„ Ù‚ÙŠÙ…Ø© rotation_index Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª.
        """
        try:
            if os.path.exists(self.ROTATION_INDEX_FILE):
                with open(self.ROTATION_INDEX_FILE, 'r') as f:
                    data = json.load(f)
                    self.rotation_index = data.get('rotation_index', 0)
            else:
                self.rotation_index = 0
        except Exception as e:
            self.send_notification('error', f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ¯ÙˆÙŠØ±: {e}")
            self.rotation_index = 0

    @staticmethod
    def round_quantity(quantity, step_size, min_qty=1e-6):
        """
        ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„ÙƒÙ…ÙŠØ© Ù„Ù„Ø£Ø³ÙÙ„ Ù„Ø£Ù‚Ø±Ø¨ Ù…Ø¶Ø§Ø¹Ù Ù„Ù„Ù€ step_sizeØŒ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ø£Ù†Ù‡Ø§ â‰¥ minQty.
        """
        rounded_qty = float(np.floor(quantity / step_size) * step_size)
        return rounded_qty if rounded_qty >= min_qty else 0

    def get_trade_limits(self, symbol):
        """ÙŠØ±Ø¬Ø¹ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„ÙƒÙ…ÙŠØ© ÙˆØ­Ø¬Ù… Ø§Ù„Ø®Ø·ÙˆØ©"""
        info = self.client.get_symbol_info(symbol)
        for f in info['filters']:
            if f['filterType'] == 'LOT_SIZE':
                return float(f['stepSize']), float(f['minQty'])
        return (0.1, 0.001)  # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯

    def update_news_sentiment(self, symbol):
        """
        ØªØ­Ø¯ÙŠØ« Ø¯Ø±Ø¬Ø© Ù…Ø¹Ù†ÙˆÙŠØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù„Ø¹Ù…Ù„Ø© Ù…Ø¹ÙŠÙ†Ø©.
        ØªÙ‚ÙˆÙ… ÙÙ‚Ø· Ø¨ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ÙØªØ§Ø­ "score" ÙˆØªØ­ØªÙØ¸ Ø¨Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø³Ø§Ø¨Ù‚Ù‹Ø§.
        """
        try:
            # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            score = self.analyze_news_sentiment(symbol)

            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            if not hasattr(self, 'news_sentiment') or not isinstance(self.news_sentiment, dict):
                self.news_sentiment = {}

            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù‚Ø§Ù…ÙˆØ³ Ù„Ù„Ø±Ù…Ø² Ù†ÙØ³Ù‡
            if symbol not in self.news_sentiment or not isinstance(self.news_sentiment[symbol], dict):
                self.news_sentiment[symbol] = {}

            # 4. ØªØ­Ø¯ÙŠØ« ÙÙ‚Ø· Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ score
            self.news_sentiment[symbol]['score'] = score

        except Exception as e:
            # 5. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø®Ø·Ø£ ÙˆØªØ¹ÙŠÙŠÙ† score = 0 ÙÙ‚Ø·
            self.send_notification('error', f'âš ï¸ ÙØ´Ù„ ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù†ÙˆÙŠØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù„Ù€ {symbol}: {e}')
            if symbol not in self.news_sentiment:
                self.news_sentiment[symbol] = {}
            self.news_sentiment[symbol]['score'] = 0

    def calculate_quantity(self, symbol):
        try:
            # 1. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±ØµÙŠØ¯ ÙˆØ§Ù„Ø³Ø¹Ø±
            balance = float(self.client.get_asset_balance('USDT')['free'])
            ticker = self.client.get_symbol_ticker(symbol=symbol)
            current_price = float(ticker['price'])
            
            if current_price <= 0:
                raise ValueError(f"Ø³Ø¹Ø± ØºÙŠØ± ØµØ§Ù„Ø­: {current_price}")
            
            # 2. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø¯ÙˆØ¯ Ø§Ù„ØªØ¯Ø§ÙˆÙ„
            step_size, min_qty = self.get_trade_limits(symbol)
            
            # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (30% Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯)
            quantity = (balance * 0.3) / current_price
            
            # 4. Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ Ù„Ù„Ø£Ø³ÙÙ„ Ø­Ø³Ø¨ step_size
            rounded_qty = float(np.floor(quantity / step_size) * step_size)
            
            # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„ÙƒÙ…ÙŠØ©
            if rounded_qty < min_qty:
                self.logger.warning("Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© (%s) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ (%s) Ù„Ù€ %s", rounded_qty, min_qty, symbol)
                return min_qty  # Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨Ø£Ù‚Ù„ ÙƒÙ…ÙŠØ© Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§
            
            return rounded_qty
            
        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ© Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
            self.send_notification('error', f"ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ© Ù„Ù€ {symbol}: {str(e)[:100]}")
            return 0

    def update_pro_signals(self, symbol):
        """
        ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù„Ø¹Ù…Ù„Ø© Ù…Ø¹ÙŠÙ†Ø© (Ù…Ø«Ù„ Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ù† Telegram Ø£Ùˆ ØªØ­Ù„ÙŠÙ„ Ø¯Ø§Ø®Ù„ÙŠ).
        ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ fetch_signals_for_symbol Ø§Ù„ØªÙŠ ØªÙØ±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø¥Ø´Ø§Ø±Ø§Øª.
        """
        try:
            signals = self.fetch_signals_for_symbol(symbol)  # ØªØ­ØªØ§Ø¬ Ù„ØªÙƒÙˆÙ† Ù…Ø¹Ø±ÙØ©

            if not hasattr(self, 'pro_signals') or not isinstance(self.pro_signals, dict):
                self.pro_signals = {}

            self.pro_signals[symbol] = signals

        except Exception as e:
            self.send_notification('error', f'âš ï¸ ÙØ´Ù„ ØªØ­Ø¯ÙŠØ« Ø¥Ø´Ø§Ø±Ø§Øª {symbol}: {e}')
            self.pro_signals[symbol] = []

    def generate_performance_report(self):
        """
        Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙˆØª Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ ØªÙ†Ø¨Ø¤Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ
        Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ.
        """
        try:
            confidence_threshold = 0.65  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„ Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ù‚ÙˆÙŠÙ‹Ø§

            report_data = {
                'timestamp': datetime.now().isoformat(),
                'models': {},
                'overall': {
                    'active_signals': 0,
                    'buy_signals': 0,
                    'neutral_signals': 0
                }
            }

            for symbol in self.symbols:
                model = self.models.get(symbol)
                if not model:
                    continue

                input_data = pd.DataFrame([[
                    0, 0, 50, 0, 1000000,
                    self.news_sentiment.get(symbol, {}).get('score', 0),
                    len(self.pro_signals.get(symbol, []))
                ]], columns=[
                    'ema20', 'ema50', 'rsi', 'macd',
                    'volume', 'news_sentiment', 'signal_count'
                ])

                signal_count = len(self.pro_signals.get(symbol, []))
                report_data['overall']['active_signals'] += signal_count

                try:
                    prediction = model.predict(input_data)
                    confidence = None

                    if hasattr(model, "predict_proba"):
                        probabilities = model.predict_proba(input_data)
                        confidence = probabilities[0][1]  # Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø´Ø±Ø§Ø¡

                    if prediction is not None and confidence is not None:
                        if prediction[0] == 1 and confidence > confidence_threshold:
                            prediction_label = 'Ø´Ø±Ø§Ø¡'
                            report_data['overall']['buy_signals'] += 1
                        else:
                            prediction_label = 'Ø§Ù†ØªØ¸Ø§Ø±'
                            report_data['overall']['neutral_signals'] += 1
                    else:
                        prediction_label = 'ØºÙŠØ± Ù…ØªØ§Ø­'

                    report_data['models'][symbol] = {
                        'prediction': prediction_label,
                        'confidence': round(confidence, 2) if confidence is not None else 'N/A',
                        'sentiment_score': round(self.news_sentiment.get(symbol, {}).get('score', 0), 2),
                        'signal_count': signal_count,
                        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M')
                    }

                except Exception as e:
                    self.logger.error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
                    report_data['models'][symbol] = {
                        'error': str(e),
                        'status': 'ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„'
                    }

            self.send_notification('report', report_data)
            return report_data

        except Exception as e:
            error_msg = f"ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {str(e)}"
            self.logger.critical(error_msg, exc_info=True)
            self.send_notification('error', error_msg)
            return {
                'error': error_msg,
                'status': 'ÙØ´Ù„ Ø­Ø±Ø¬'
            }

    def save_state(self):
        state = {
            'current_positions': self.current_positions,
            'last_peaks': self.last_peaks,
            'trailing_stops': self.trailing_stops
        }
        try:
            with open('state.json', 'w') as f:
                json.dump(state, f)
            print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­.")
            self.send_notification('update', 'ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù state.json')
        except Exception as e:
            try:
                # 1. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ù„ÙˆØ¬Ø± Ø§Ù„Ø±Ø³Ù…ÙŠ Ø¨ØµÙŠØºØ© lazy formatting
                self.logger.error(
                    "ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© - Ø§Ù„Ø®Ø·Ø£: %s",
                    str(e),
                    exc_info=True,
                    stack_info=True,
                    extra={'section': 'state_saving'}
                )

                # 2. Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø¹Ø§Ø¬Ù„ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©
                self.send_notification(
                    'system_error',
                    f"""
                    âš ï¸ ÙØ´Ù„ Ø­Ø±Ø¬ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© âš ï¸
                    
                    ğŸ“› Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£: {type(e).__name__}
                    ğŸ“Œ Ø§Ù„ØªÙØ§ØµÙŠÙ„: {str(e)[:200]}
                    ğŸ“„ Ø§Ù„Ù…Ù„Ù: {__file__}
                    â° Ø§Ù„ÙˆÙ‚Øª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                    """
                )

                # 3. Ù…Ø­Ø§ÙˆÙ„Ø© Ø­ÙØ¸ Ø¨Ø¯Ø§Ø¦ÙŠØ© Ù„Ù„Ø®Ø·Ø£ ÙƒÙ…Ù„Ù Ø·ÙˆØ§Ø±Ø¦
                try:
                    with open('state_save_failure.txt', 'a', encoding='utf-8') as f:
                        f.write(f"[{datetime.now()}] State Save Failure: {str(e)}\n")
                        traceback.print_exc(file=f)
                except Exception as file_err:
                    self.logger.critical("ÙØ´Ù„ Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ø·ÙˆØ§Ø±Ø¦: %s", file_err)

            except Exception as logging_error:
                # 4. Ù†Ø¸Ø§Ù… Ø·ÙˆØ§Ø±Ø¦ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
                try:
                    logging.basicConfig(level=logging.CRITICAL)
                    logging.critical("Total failure: %s\nOriginal error: %s", logging_error, e)
                except Exception as fallback_error:
                    sys.stderr.write(f"[ULTIMATE FALLBACK] State save failed: {fallback_error}\n")

    def load_state(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙØ­Øµ Ø§Ù„ØªÙƒØ§Ù…Ù„"""
        try:
            state_file = 'state.json'
            
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
            if not os.path.exists(state_file):
                self.logger.info("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù state.json. Ø³ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¨ÙˆØª Ø¨Ø­Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©.")
                self._initialize_default_state()
                return

            # 2. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­ØªÙ‡
            with open(state_file, 'r') as f:
                try:
                    state = json.load(f)
                except json.JSONDecodeError as e:
                    raise ValueError(f"Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„Ø© ØªØ§Ù„Ù ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡ØªÙ‡: {str(e)}")

            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            required_keys = ['current_positions', 'last_peaks', 'trailing_stops']
            for key in required_keys:
                if key not in state:
                    raise ValueError(f"Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø­Ø§Ù„Ø©: {key}")

            # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if not isinstance(state['current_positions'], dict):
                raise TypeError("current_positions ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ÙˆØ¹ dictionary")
            
            if not isinstance(state['last_peaks'], dict):
                raise TypeError("last_peaks ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ÙˆØ¹ dictionary")
                
            if not isinstance(state['trailing_stops'], dict):
                raise TypeError("trailing_stops ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ÙˆØ¹ dictionary")

            # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø±Ù‚Ù…ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            if 'checksum' in state:
                self._verify_state_checksum(state)

            # 6. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø±Ù…ÙˆØ²
            for symbol in state['current_positions']:
                if symbol not in self.symbols:
                    self.logger.warning("Ø±Ù…Ø² ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: %s", symbol)

            # 7. ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù‚ÙŠÙ… Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©
            self.current_positions = {
                k: v for k, v in state['current_positions'].items() 
                if self._validate_position_data(v)
            }
            
            self.last_peaks = {
                k: float(v) for k, v in state['last_peaks'].items()
                if k in self.symbols and isinstance(v, (int, float))
            }
            
            self.trailing_stops = {
                k: float(v) for k, v in state['trailing_stops'].items()
                if k in self.symbols and isinstance(v, (int, float))
            }

            self.logger.info("ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©")
            self.send_notification('update', 'ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ù† state.json Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚')

        except Exception as e:
            self._handle_state_loading_error(e, state_file)

    def _initialize_default_state(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
        self.current_positions = {}
        self.last_peaks = {}
        self.trailing_stops = {}
        self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©")

    @staticmethod
    def _validate_position_data(position_data):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ²"""
        required_keys = ['entry_price', 'quantity', 'timestamp']
        if not all(k in position_data for k in required_keys):
            return False
            
        try:
            float(position_data['entry_price'])
            float(position_data['quantity'])
            datetime.fromisoformat(position_data['timestamp'])
            return True
        except (ValueError, TypeError):
            return False

    @staticmethod
    def _verify_state_checksum(state):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† checksum Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)"""
        data_copy = state.copy()
        checksum = data_copy.pop('checksum', None)
        
        if checksum is not None:
            calculated = hashlib.sha256(
                json.dumps(data_copy, sort_keys=True).encode()
            ).hexdigest()
            
            if calculated != checksum:
                raise ValueError("Checksum ØºÙŠØ± Ù…ØªØ·Ø§Ø¨Ù‚ - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ø¹Ø·ÙˆØ¨Ø©")

    def _handle_state_loading_error(self, error, state_file):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©"""
        error_msg = f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©: {str(error)}"
        self.logger.error(error_msg, exc_info=True)
        
        # Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        corrupted_file = f"state_corrupted_{timestamp}.json"
        shutil.copyfile(state_file, corrupted_file)
        
        self.logger.info("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù: %s", corrupted_file)
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        self._initialize_default_state()
        
        self.send_notification(
            'error',
            f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©\n"
            f"ğŸ“› {type(error).__name__}\n"
            f"ğŸ’¾ ØªÙ… Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù„Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ\n"
            f"â° {datetime.now().strftime('%H:%M')}"
        )

    def handle_binance_error(self, e):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Binance Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"""
        if isinstance(e, binance.exceptions.BinanceAPIException) and e.code == -1003:
            self.send_notification('warning', "ØªÙ… ØªØ¬Ø§ÙˆØ² Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù„Ù€ Binance - Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 60 Ø«Ø§Ù†ÙŠØ©")
            time.sleep(60)
            return True  # Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
        return False

    def safe_api_request(self, request_func, rate_limit=None, max_retries=3, base_delay=1):
        """Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹:
        - Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª (rate limiting)
        - Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù…Ø¹ exponential backoff
        - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø£Ø®Ø·Ø§Ø¡ API
        """
        try:
            # Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
            if rate_limit and rate_limit > 0:
                time.sleep(1.0 / rate_limit)

            for attempt in range(max_retries):
                try:
                    response = request_func()

                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ HTTP
                    if hasattr(response, 'status_code'):
                        if response.status_code == 429:  # Rate limited
                            retry_after = int(response.headers.get('Retry-After', 60))
                            self.logger.warning("ØªÙ… ØªØ¬Ø§ÙˆØ² Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ %s Ø«Ø§Ù†ÙŠØ©", retry_after)
                            time.sleep(retry_after)
                            continue

                        if response.status_code >= 500:  # Server error
                            raise APIError(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…: {response.status_code}")

                    return response

                except (requests.Timeout, requests.ConnectionError) as e:
                    self.logger.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© %d/%d): %s", 
                                      attempt + 1, max_retries, str(e))
                    if attempt == max_retries - 1:
                        raise APIConnectionError(f"ÙØ´Ù„ Ø¨Ø¹Ø¯ {max_retries} Ù…Ø­Ø§ÙˆÙ„Ø§Øª")
                    time.sleep(base_delay * (2 ** attempt))  # Exponential backoff

                except BinanceAPIException as e:
                    self.logger.error("Ø®Ø·Ø£ Binance API (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© %d/%d): %s", 
                                      attempt + 1, max_retries, str(e))
                    if attempt == max_retries - 1:
                        self.handle_binance_error(e)  # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø£Ø®Ø·Ø§Ø¡ Binance
                        raise
                    time.sleep(base_delay * (2 ** attempt))

        except Exception as e:
            self.logger.critical("ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ safe_api_request: %s", str(e), exc_info=True)
            raise APIError(f"ÙØ´Ù„ ÙÙŠ Ø·Ù„Ø¨ API: {str(e)}")

    def check_api_health(self):
        try:
            response = self.client.ping()
            if not response:
                raise ConnectionError("No response from API")
        except Exception as e:
            self.send_notification('error', f'ÙØ´Ù„ ÙÙŠ Ø§ØªØµØ§Ù„ API: {str(e)}')
            return False
        return True
        
    @staticmethod
    def _retry_api_request(request_func, *args, max_retries=3, base_delay=1, logger=None, **kwargs):
        """Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø®Ø§Øµ Ø¨Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
        for attempt in range(max_retries):
            try:
                response = request_func(*args, **kwargs)
                if hasattr(response, 'status_code') and response.status_code != 200:
                    raise APIError(
                        message=f"API response returned status code {response.status_code}",
                        status_code=response.status_code
                    )
                return response
            except Exception as e:
                if logger:
                    logger.warning(f"ğŸ“› Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} ÙØ´Ù„Øª: {str(e)}")
                else:
                    print(f"ğŸ“› Ù…Ø­Ø§ÙˆÙ„Ø© {attempt+1} ÙØ´Ù„Øª: {str(e)}")
                if attempt == max_retries - 1:
                    raise
                time.sleep(base_delay * (2 ** attempt))  # Exponential backoff

    def safe_api_call(self, func, *args, **kwargs):
        """
        ØªÙ†ÙÙŠØ° Ø¢Ù…Ù† Ù„Ø·Ù„Ø¨Ø§Øª API Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª Ù…Ø­Ø¯Ø¯Ø©
        """
        try:
            return func(*args, **kwargs)

        except requests.exceptions.Timeout as e:
            self.logger.warning("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨: %s", str(e))
            raise APITimeoutError(f"Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}")

        except requests.exceptions.ConnectionError as e:
            self.logger.error("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: %s", str(e))
            raise APIConnectionError(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…: {str(e)}")

        except binance.exceptions.BinanceAPIException as e:
            error_msg = f"Ø®Ø·Ø£ Binance API (ÙƒÙˆØ¯ {e.status_code}): {e.message}"
            self.logger.error(error_msg)
            raise BinanceAPIError(error_msg)

        except json.JSONDecodeError as e:
            self.logger.error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON: %s", str(e))
            raise InvalidResponseError("Ø§Ø³ØªØ¬Ø§Ø¨Ø© API ØºÙŠØ± ØµØ§Ù„Ø­Ø©")

        except Exception as e:
            self.logger.critical("Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: %s: %s", type(e).__name__, str(e))
            raise APIError(f"ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ API: {str(e)}")

    def process_trade(self, symbol):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙÙ‚Ø© Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø¨Ø´ÙƒÙ„ ÙØ±Ø¯ÙŠ
        """
        try:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
            market_data = self.safe_api_call(
                self.client.get_historical_klines,
                symbol, '1h', '1 day ago UTC'
            )

            if not market_data or len(market_data) == 0:
                self.logger.warning("ğŸš« Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù€ %s", symbol)
                return None

            # ØªØ­Ù„ÙŠÙ„ Ø¢Ø®Ø± Ø¥ØºÙ„Ø§Ù‚
            latest_close = float(market_data[-1][4])
            self.logger.debug("ğŸ“Š Ø¢Ø®Ø± Ø¥ØºÙ„Ø§Ù‚ Ù„Ù€ %s: %s", symbol, latest_close)

            # ØªÙ†ÙÙŠØ° Ø§Ù„ØµÙÙ‚Ø©
            order = self.safe_api_call(
                self.client.create_order,
                symbol=symbol,
                side='BUY',
                type='MARKET',
                quantity=self.calculate_quantity(symbol)
            )

            return order

        except APITimeoutError:
            self.send_notification('warning', 'Ù…Ù‡Ù„Ø© Ø·Ù„Ø¨ API - Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©...')
            return None

        except BinanceAPIException as e:
            if e.code == -1003:
                self.send_notification('warning', 'ØªÙ… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª - Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 60 Ø«Ø§Ù†ÙŠØ©')
                time.sleep(60)
                return self.process_trade(symbol)

        except InsufficientFundsError:
            self.send_notification('error', 'Ø±ØµÙŠØ¯ ØºÙŠØ± ÙƒØ§ÙÙŠ Ù„Ù„ØªÙ†ÙÙŠØ°')
            return None

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙÙ‚Ø©: %s", str(e))
            self.send_notification('error', f'ÙØ´Ù„ ØªÙ†ÙÙŠØ° Ø§Ù„ØµÙÙ‚Ø©: {type(e).__name__}')
            return None

    def execute_trade(self, symbol):
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØµÙÙ‚Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¯ 6$ ÙƒØ­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø±"""
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø± (Ø­Ø¯ Ø£Ø¯Ù†Ù‰ 6$ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 15%)
            free_balance = float(self.client.get_asset_balance('USDT')['free'])
            min_required_balance = 6.0  # Ø­Ø¯ Ø«Ø§Ø¨Øª = 6 Ø¯ÙˆÙ„Ø§Ø±

            if free_balance < min_required_balance:
                msg = (
                    f"ğŸ›‘ Ø±ØµÙŠØ¯ ØºÙŠØ± ÙƒØ§ÙÙ Ù„Ù€ {symbol}\n"
                    f"Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø±: {free_balance:.2f} USDT\n"
                    f"Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {min_required_balance} USDT"
                )
                self.logger.warning(msg)
                self.send_notification('warning', msg)
                return None

            # 2. Ù…ØªØ§Ø¨Ø¹Ø© Ø¨Ø§Ù‚ÙŠ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØµÙÙ‚Ø© (Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¹Ø±ØŒ Ø¥Ù„Ø®...)
            data = self.safe_api_request(
                lambda: self.client.get_historical_klines(symbol, '1h', '1 day ago UTC'),
                rate_limit=1
            )

            if not data or len(data) == 0:
                self.logger.warning("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ %s", symbol)
                return None

            latest_close = float(data[-1][4])
            if latest_close > 10:  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø£Ùˆ Ø¥Ø²Ø§Ù„Ø© Ù‡Ø°Ø§ Ø§Ù„Ø´Ø±Ø·
                self.logger.info("â›” Ø¥Ù„ØºØ§Ø¡ Ø´Ø±Ø§Ø¡ %s (Ø§Ù„Ø³Ø¹Ø± Ù…Ø±ØªÙØ¹: %.2f USDT)", symbol, latest_close)
                return None

            quantity = self.calculate_quantity(symbol)
            if quantity <= 0:
                return None

            order = self.client.create_order(
                symbol=symbol,
                side='BUY',
                type='MARKET',
                quantity=quantity
            )
            return order

        except binance.exceptions.BinanceAPIException as api_error:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Binance API Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
            error_msg = f"Ø®Ø·Ø£ Binance API (ÙƒÙˆØ¯ {api_error.code}): {api_error.message}"
            self.logger.error(error_msg)

            if api_error.code == -2015:  # Invalid API key
                self.send_notification('critical', 'API key Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©!')
                self.shutdown_bot()
            elif api_error.code == -1003:  # IP banned
                self.send_notification('critical', 'ØªÙ… Ø­Ø¸Ø± IP!')
            elif api_error.code == -1013:  # Invalid quantity
                self.send_notification('error', 'Ø§Ù„ÙƒÙ…ÙŠØ© ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù„Ø·Ù„Ø¨')
            elif api_error.code == -2010:  # Insufficient balance
                self.send_notification('error', 'Ø±ØµÙŠØ¯ ØºÙŠØ± ÙƒØ§ÙÙŠ Ù„Ù„ØªÙ†ÙÙŠØ°')
            else:
                self.send_notification('error', f"Ø®Ø·Ø£ ÙÙŠ Binance API: {api_error.message}")

            return None

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØªÙ†ÙÙŠØ° Ø§Ù„ØµÙÙ‚Ø©: %s", str(e), exc_info=True)
            self.send_notification('error', f"âŒ ÙØ´Ù„ ÙÙŠ {symbol}: {str(e)[:100]}")
            return None

    def get_historical_data(self, symbol: str, interval: str = '5m', limit: int = None, days: int = None) -> pd.DataFrame:
        """
        Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© ØªØ¯Ø¹Ù… ÙƒÙ„Ø§ Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ† (limit Ùˆ days)
        Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‚ÙŠÙˆØ¯ Binance API

        Parameters:
            symbol: Ø±Ù…Ø² Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Ù…Ø«Ù„ BTCUSDT)
            interval: Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ (1m, 5m, 15m, 1h, ...)
            limit: Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            days: Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        """
        BINANCE_MAX_LIMIT = 1000  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Binance API

        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ limit Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙŠØ§Ù…
            if days is not None:
                intervals_per_day = {
                    '1m': 1440,
                    '5m': 288,
                    '15m': 96,
                    '1h': 24,
                    '4h': 6,
                    '1d': 1
                }
                requested_limit = intervals_per_day.get(interval, 288) * days

                if limit is None or requested_limit < limit:
                    limit = requested_limit

            # Ø¶Ø¨Ø· Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
            if limit and limit > BINANCE_MAX_LIMIT:
                self.logger.warning("ØªÙ… ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¯ Ù…Ù† %s Ø¥Ù„Ù‰ %s Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙˆØ¯ Binance", limit, BINANCE_MAX_LIMIT)
                limit = BINANCE_MAX_LIMIT

            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            klines = self.client.get_klines(
                symbol=symbol,
                interval=interval,
                limit=limit or 100  # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            )

            if not klines:
                raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªÙ„Ù…Ø©")

            df = pd.DataFrame(klines, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'num_trades',
                'taker_buy_base_vol', 'taker_buy_quote_vol', 'ignore'
            ])

            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            df = df[['open', 'high', 'low', 'close', 'volume']].astype(float)

            if df.empty:
                raise ValueError("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ÙØ§Ø±ØºØ©")

            return df

        except Exception as e:
            error_msg = f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {symbol} Ø¹Ù„Ù‰ {interval}"
            if limit: error_msg += f" (limit={limit})"
            if days: error_msg += f" (days={days})"
            error_msg += f": {str(e)}"

            self.logger.error(error_msg)
            self.send_notification('error', error_msg[:200])
            return None

    def analyze_multiple_timeframes(self, symbol: str) -> dict:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© (5m, 15m, 1h) Ù„Ø¹Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø©

        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙØµÙ„Ø© Ù„ÙƒÙ„ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ
        - ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        - ØªØ³Ø¬ÙŠÙ„ ØªØ­Ø°ÙŠØ±Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø©
        - ÙƒÙØ§Ø¡Ø© ÙÙŠ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯

        Returns:
            dict: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„ÙƒÙ„ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ Ø£Ùˆ {} Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        """
        analysis = {}
        required_indicators = ['ema20', 'ema50', 'rsi', 'macd', 'volume']

        for interval in ['5m', '15m', '1h']:
            try:
                # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                df = self.get_historical_data(symbol, interval=interval, limit=100)
                if df is None or df.empty:
                    self.logger.warning("Ø¨ÙŠØ§Ù†Ø§Øª %s Ø¹Ù„Ù‰ %s ÙØ§Ø±ØºØ©", symbol, interval)
                    continue

                # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                df = self.calculate_technical_indicators(df)

                # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                if not all(indicator in df.columns for indicator in required_indicators):
                    missing = [ind for ind in required_indicators if ind not in df.columns]
                    self.logger.warning("Ù…Ø¤Ø´Ø±Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù€ %s Ø¹Ù„Ù‰ %s: %s", symbol, interval, missing)
                    continue

                # 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ…
                analysis[interval] = {
                    'ema20': df['ema20'].iloc[-1],
                    'ema50': df['ema50'].iloc[-1],
                    'rsi': df['rsi'].iloc[-1],
                    'macd': df['macd'].iloc[-1],
                    'volume': df['volume'].iloc[-1]
                }

            except Exception as e:
                self.logger.error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ %s Ù„Ù€ %s: %s", interval, symbol, str(e), exc_info=True)
                continue

        return analysis

    @staticmethod
    def _is_connected(timeout=5):
        """Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª"""
        try:
            response = requests.get("https://api.binance.com/api/v3/ping", timeout=timeout)
            return response.status_code == 200
        except Exception:
            return False

    def check_internet_connection(self, timeout=5, retries=3):
        """ÙØ­Øµ Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"""
        for i in range(retries):
            if self._is_connected(timeout):
                return True

            if i < retries - 1:  # Ù„Ø§ ØªÙ†Ø§Ù… Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
                time.sleep(2 ** i)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ù‡Ù„Ø© ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹
        
        self.send_notification('connection', f'ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ {retries} Ù…Ø­Ø§ÙˆÙ„Ø§Øª')
        return False

    def handle_connection_loss(self):
        """Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø¹Ù†Ø¯ ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„"""
        self.send_notification('error', 'Ø§Ù†Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©...')
        time.sleep(60)  # Ø§Ù†ØªØ¸Ø± Ø¯Ù‚ÙŠÙ‚Ø© Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©

    @staticmethod
    def initialize_ml_model():
        """
        ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… XGBoost Ø¯Ø§Ø®Ù„ Pipeline
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - ØªØ¶Ù…ÙŠÙ† StandardScaler Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        - Ø§Ø³ØªØ®Ø¯Ø§Ù… XGBClassifier Ø¨ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ù„ØªÙ‚Ù„ÙŠÙ„ overfitting
        - ØªÙƒÙˆÙŠÙ† Ø«Ø§Ø¨Øª ÙˆØ¹Ø´ÙˆØ§Ø¦ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        
        Returns:
            sklearn.pipeline.Pipeline: Ù†Ù…ÙˆØ°Ø¬ Ù…Ù‡ÙŠØ£ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø£Ùˆ Ø§Ù„ØªÙ†Ø¨Ø¤
        
        Ø§Ù„ØªÙØ§ØµÙŠÙ„:
        - learning_rate=0.05: ØªØ¹Ù„Ù… ØªØ¯Ø±ÙŠØ¬ÙŠ Ø£Ø¯Ù‚
        - max_depth=5: Ø¹Ù…Ù‚ Ù…Ø­Ø¯ÙˆØ¯ Ù„Ù„Ø´Ø¬Ø±Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        - n_estimators=300: Ø¹Ø¯Ø¯ Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ø£Ø´Ø¬Ø§Ø± Ù„Ø¯Ù‚Ø© Ø£ÙØ¶Ù„
        - subsample=0.8: Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ø¬Ø²Ø¦ÙŠØ© Ù„ØªÙ‚ÙˆÙŠØ© Ø§Ù„ØªØ¹Ù…ÙŠÙ…
        - colsample_bytree=0.8: Ø§Ø®ØªÙŠØ§Ø± Ø¬Ø²Ø¦ÙŠ Ù„Ù„Ù…ÙŠØ²Ø§Øª Ù„ÙƒÙ„ Ø´Ø¬Ø±Ø©
        """
        return Pipeline([
            ('scaler', StandardScaler()),
            ('xgb', XGBClassifier(
                objective=TradingBot.self.OBJECTIVE_BINARY,
                learning_rate=0.05,
                max_depth=5,
                n_estimators=300,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                eval_metric='logloss'
            ))
        ], memory=TradingBot.memory)

    def retrain_model(self, symbol):        
            self.train_ml_model(symbol)  # Ø³ÙŠØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„ÙƒÙ„ Ø¹Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø­Ø¯Ø©
            file_path = f"training_data_{symbol}.csv"
            if not os.path.exists(file_path):
                self.send_notification('warning', f"âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {symbol}")
                return

            try:
                df = pd.read_csv(file_path)
                df = df.dropna()

                required_columns = [
                    'ema20', 'ema50', 'rsi', 'macd',
                    'volume', 'news_sentiment', 'signal_count', 'target'
                ]
                if not all(col in df.columns for col in required_columns):
                    self.send_notification('error', f"âŒ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù†Ø§Ù‚ØµØ© ÙÙŠ {symbol}")
                    return

                X = df[required_columns[:-1]]
                y = df['target']

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                model = self.initialize_ml_model()
                model.fit(X_train, y_train)

                y_pred = model.predict(X_test)
                acc = accuracy_score(y_test, y_pred)
                prec = precision_score(y_test, y_pred, zero_division=0)
                rec = recall_score(y_test, y_pred, zero_division=0)

                self.send_notification('report', f"ğŸ“Š {symbol} â€” Ø¯Ù‚Ø©: {acc:.4f}, Ø§Ù„Ø¯Ù‚Ø©: {prec:.4f}, Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹: {rec:.4f}")

                model_path = f"xgb_model_{symbol}.pkl"
                joblib.dump(model, open(model_path, 'wb'))
                self.models[symbol] = model

            except Exception as e:
                self.send_notification('error', f"âŒ ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}: {e}")

    def start_bot(self):
        """ÙŠØ¨Ø¯Ø£ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª Ù…Ø¹ Ø¥Ø´Ø¹Ø§Ø±"""
        self.is_running = True
        self.start_time = datetime.now()
        self.send_notification('start')
        print("ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª")

    def shutdown_bot(self, reason="Ø¥ÙŠÙ‚Ø§Ù Ø·Ø¨ÙŠØ¹ÙŠ"):
        """ÙŠÙˆÙ‚Ù Ø§Ù„Ø¨ÙˆØª Ù…Ø¹ Ø¥Ø´Ø¹Ø§Ø±"""
        self.is_running = False
        self.send_notification('shutdown', {'reason': reason})
        print(f"ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨ÙˆØª. Ø§Ù„Ø³Ø¨Ø¨: {reason}")

    # Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„
    def calculate_technical_indicators(self, df):
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ù…Ø¹ Ø¶Ù…Ø§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø© Ø¶Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        """
        try:
            # ===== 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø© =====
            required_columns = {
                'open': 'Ø³Ø¹Ø± Ø§Ù„Ø§ÙØªØªØ§Ø­',
                'high': 'Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø±',
                'low': 'Ø£Ù‚Ù„ Ø³Ø¹Ø±',
                'close': 'Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚',
                'volume': 'Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„'
            }

            missing_columns = [name for col, name in required_columns.items()
                               if col not in df.columns]
            if missing_columns:
                error_msg = f"Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø©: {', '.join(missing_columns)}"
                self.logger.error(error_msg)
                raise ValueError(error_msg)

            if df[list(required_columns.keys())].isnull().any().any():
                error_msg = "ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"
                self.logger.error(error_msg)
                raise ValueError(error_msg)

            # ===== 2. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© =====
            indicators = {}

            indicators['ema20'] = self._safe_calculate_indicator(
                lambda: EMAIndicator(close=df['close'], window=20).ema_indicator(),
                'EMA 20'
            )

            indicators['ema50'] = self._safe_calculate_indicator(
                lambda: EMAIndicator(close=df['close'], window=50).ema_indicator(),
                'EMA 50'
            )

            indicators['rsi'] = self._safe_calculate_indicator(
                lambda: RSIIndicator(close=df['close'], window=14).rsi(),
                'RSI'
            )

            macd_line = self._safe_calculate_indicator(
                lambda: MACD(close=df['close']).macd(),
                'MACD Line'
            )
            signal_line = self._safe_calculate_indicator(
                lambda: MACD(close=df['close']).macd_signal(),
                'MACD Signal'
            )

            if macd_line is not None and signal_line is not None:
                indicators['macd'] = macd_line
                indicators['macd_signal'] = signal_line

            indicators['bb_upper'] = self._safe_calculate_indicator(
                lambda: BollingerBands(close=df['close']).bollinger_hband(),
                'Bollinger Upper'
            )

            indicators['bb_lower'] = self._safe_calculate_indicator(
                lambda: BollingerBands(close=df['close']).bollinger_lband(),
                'Bollinger Lower'
            )

            indicators['adx'] = self._safe_calculate_indicator(
                lambda: ADXIndicator(
                    high=df['high'],
                    low=df['low'],
                    close=df['close'],
                    window=14
                ).adx(),
                'ADX'
            )

            # ===== 3. Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ =====
            for name, values in indicators.items():
                if values is not None:
                    df[name] = values

            # ===== 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ =====
            required_indicators = ['ema20', 'ema50', 'rsi']
            for indicator in required_indicators:
                if indicator not in df.columns or df[indicator].isnull().all():
                    error_msg = f"ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: {indicator}"
                    self.logger.error(error_msg)
                    raise RuntimeError(error_msg)

            self.logger.info("ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
            return df

        except ValueError as ve:
            self.send_notification(
                'error',
                f"ğŸ“Š Ø®Ø·Ø£ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª\nğŸ“Œ {str(ve)}\nâ° {datetime.now().strftime('%H:%M')}"
            )
            raise

        except Exception as e:
            error_msg = f"ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {type(e).__name__}: {str(e)}"
            self.logger.critical(error_msg, exc_info=True)
            self.send_notification(
                'error',
                f"ğŸ“Š Ø§Ù†Ù‡ÙŠØ§Ø± Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª\nğŸ“› {type(e).__name__}\nâ° {datetime.now().strftime('%H:%M')}"
            )
            raise

    def _safe_calculate_indicator(self, indicator_func, indicator_name):
        """
        Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡

        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ù…Ø­Ø³ÙˆØ¨
        - ØªØ³Ø¬ÙŠÙ„ Ù…ÙØµÙ„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        - Ø¹Ø¯Ù… ØªÙˆÙ‚Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¹Ù†Ø¯ ÙØ´Ù„ Ù…Ø¤Ø´Ø± ÙˆØ§Ø­Ø¯
        - ØªÙˆØ«ÙŠÙ‚ ÙƒØ§Ù…Ù„ Ù„Ù„Ø¯Ø§Ù„Ø©

        Args:
            indicator_func: Ø¯Ø§Ù„Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø± (lambda function)
            indicator_name: Ø§Ø³Ù… ÙˆØµÙÙŠ Ù„Ù„Ù…Ø¤Ø´Ø±

        Returns:
            pandas.Series: Ø³Ù„Ø³Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±
            None: Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨

        Examples:
            >>> _safe_calculate_indicator(lambda: EMAIndicator(close=df['close']).ema_indicator(), "EMA 20")
        """
        try:
            # 1. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±
            result = indicator_func()

            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„ÙŠØ³Øª ÙØ§Ø±ØºØ©
            if result is None:
                raise ValueError("Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ø£Ø¹Ø§Ø¯Øª Ù‚ÙŠÙ…Ø© None")

            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ ÙˆÙ†ÙˆØ¹ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if not isinstance(result, pd.Series):
                raise TypeError(f"Ø§Ù„Ù†Ø§ØªØ¬ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† pandas.Series ÙˆÙ„ÙŠØ³ {type(result)}")

            # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ©
            if result.isnull().any():
                nan_count = result.isnull().sum()
                raise ValueError(f"ÙŠÙˆØ¬Ø¯ {nan_count} Ù‚ÙŠÙ… ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ù†Ø§ØªØ¬")

            # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·ÙˆÙ„ Ø§Ù„Ø³Ù„Ø³Ù„Ø©
            if len(result) == 0:
                raise ValueError("Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø© ÙØ§Ø±ØºØ©")

            return result

        except ValueError as ve:
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ù‚ÙŠÙ…Ø© Ù…Ø¤Ø´Ø± {indicator_name}: {str(ve)}"
            self.logger.warning(error_msg)
            return None

        except TypeError as te:
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ù†ÙˆØ¹ Ù…Ø¤Ø´Ø± {indicator_name}: {str(te)}"
            self.logger.warning(error_msg)
            return None

        except Exception as e:
            error_msg = f"ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± {indicator_name}: {type(e).__name__}: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            return None

    def check_timeframe_divergence(self, symbol):
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªØ¨Ø§Ø¹Ø¯ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        """
        analysis = self.analyze_multiple_timeframes(symbol)
        
        if not all(k in analysis for k in ['5m', '15m', '1h']):
            return False

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ… Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±
        rsi_5m = analysis['5m']['rsi']
        rsi_15m = analysis['15m']['rsi']
        macd_5m = analysis['5m']['macd']
        macd_15m = analysis['15m']['macd']

        # ØªØ¨Ø§Ø¹Ø¯ RSI
        rsi_divergence = (rsi_5m > 70 > rsi_15m) or (rsi_5m < 30 < rsi_15m)

        # ØªØ¨Ø§Ø¹Ø¯ MACD
        macd_divergence = (macd_5m > 0 > macd_15m) or (macd_5m < 0 < macd_15m)

        return rsi_divergence or macd_divergence

    def backtest_strategy(self, symbol: str, days: int = 90, interval: str = '5m') -> dict:
        """
        Ø§Ø®ØªØ¨Ø§Ø± ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ø§Ø¨Ù‚Ø©
        """
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
            df = self.get_historical_data(symbol, interval=interval, limit=days*288)  # 288 = Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…ÙˆØ¹ ÙÙŠ Ø§Ù„ÙŠÙˆÙ… Ù„Ù€5m

            if df is None or len(df) < 100:
                return {'error': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±'}

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
            df = self.calculate_technical_indicators(df)

            # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØµÙÙ‚Ø§Øª
            trades = []
            in_position = False
            entry_price = 0
            entry_time = None

            for i in range(1, len(df)):
                current = df.iloc[i]
                previous = df.iloc[i-1]

                # Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… previous
                entry_conditions = (
                    current['ema20'] > current['ema50'] and
                    previous['ema20'] <= previous['ema50'] and
                    current['rsi'] > 50 and
                    current['macd'] > current['macd_signal'] and
                    not in_position
                )

                # Ø´Ø±ÙˆØ· Ø§Ù„Ø®Ø±ÙˆØ¬ ÙƒÙ…Ø§ Ù‡ÙŠ Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„
                exit_conditions = (
                    in_position and 
                    (current['close'] < current['ema20'] or
                     current['rsi'] > 70 or
                     current['close'] <= entry_price * 0.95)
                )

                # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø®ÙˆÙ„
                if entry_conditions:
                    in_position = True
                    entry_price = current['close']
                    entry_time = current.name

                # ØªÙ†ÙÙŠØ° Ø§Ù„Ø®Ø±ÙˆØ¬
                elif exit_conditions and in_position:
                    exit_price = current['close']
                    profit_pct = (exit_price - entry_price) / entry_price * 100
                    duration = (current.name - entry_time).total_seconds() / 60  # Ø§Ù„Ù…Ø¯Ø© Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚

                    trades.append({
                        'entry_price': entry_price,
                        'exit_price': exit_price,
                        'profit_pct': profit_pct,
                        'duration': duration,
                        'entry_time': entry_time,
                        'exit_time': current.name
                    })

                    in_position = False

            # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
            if not trades:
                return {'error': 'Ù„Ù… ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ø£ÙŠ ØµÙÙ‚Ø§Øª Ø®Ù„Ø§Ù„ Ø§Ù„ÙØªØ±Ø©'}

            winning_trades = [t for t in trades if t['profit_pct'] > 0]
            losing_trades = [t for t in trades if t['profit_pct'] <= 0]

            results = {
                'total_trades': len(trades),
                'win_rate': len(winning_trades) / len(trades),
                'avg_profit': sum(t['profit_pct'] for t in trades) / len(trades),
                'max_profit': max(t['profit_pct'] for t in trades),
                'max_loss': min(t['profit_pct'] for t in trades),
                'profit_factor': (sum(t['profit_pct'] for t in winning_trades) / 
                                  abs(sum(t['profit_pct'] for t in losing_trades))) if losing_trades else float('inf'),
                'avg_duration': sum(t['duration'] for t in trades) / len(trades),
                'trades': trades[:50]  # Ø­ÙØ¸ Ø£ÙˆÙ„ 50 ØµÙÙ‚Ø© ÙÙ‚Ø· Ù„Ù„ØªØ­Ù„ÙŠÙ„
            }

            return results

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
            return {'error': str(e)}

    def optimize_entry_conditions(self, symbol: str, test_periods: list = None) -> dict:
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø´Ø¨ÙƒÙŠ Ù…Ø¹ ØªÙ‚ÙŠÙŠÙ… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³

        Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
        - ØªØ­Ù„ÙŠÙ„ Ø¹Ø¯Ø© ÙØªØ±Ø§Øª Ø²Ù…Ù†ÙŠØ©
        - Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù…Ø«Ù„Ù‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡
        """
        if test_periods is None:
            test_periods = [30, 60, 90]
        try:
            # 1. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            data = self._load_training_data(symbol)
            if data is None:
                return {'error': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ÙƒØ§ÙÙŠØ©'}

            # 2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠ
            X = data.drop('target', axis=1)
            y = data['target']

            # 3. ØªØ¹Ø±ÙŠÙ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¨Ø­Ø«
            param_grid = {
                'rsi_min': [40, 45, 50, 55],
                'ema_cross': [True, False],
                'macd_condition': [True, False],
                'news_threshold': [0.1, 0.2, 0.3],
                'min_signals': [1, 2, 3],
                'timeframe_confirmations': [1, 2]
            }

            # 4. Ø¯Ø§Ù„Ø© ØªÙ‚ÙŠÙŠÙ… Ù…Ø®ØµØµØ© ØªØ£Ø®Ø° ÙÙŠ Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ø±Ø¨Ø­ÙŠØ©
            def profit_scorer(estimator, X, _):
                y_pred = estimator.predict(X)
                profit = (y_pred * X['expected_profit']).sum()
                return profit

            # 5. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø´Ø¨ÙƒÙŠ
            grid = GridSearchCV(
                estimator=XGBClassifier(),
                param_grid=param_grid,
                scoring=profit_scorer,
                cv=TimeSeriesSplit(n_splits=3),
                n_jobs=-1,
                verbose=1
            )

            # 6. ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«
            grid.fit(X, y)

            # 7. ØªØ­Ù„ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø£Ù…Ø«Ù„
            time_analysis = self._analyze_optimal_times(data)

            # 8. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            best_params = {
                **grid.best_params_,
                'best_score': grid.best_score_,
                'time_analysis': time_analysis
            }

            self._save_optimization_results(symbol, best_params)

            return best_params

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
            return {'error': str(e)}

    def _analyze_optimal_times(self, data: pd.DataFrame) -> dict:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…Ø«Ù„Ù‰ Ù„Ù„ØªØ¯Ø§ÙˆÙ„

        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø³Ø§Ø¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…
        2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø£ÙŠØ§Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹
        3. ØªØ­Ø¯ÙŠØ¯ ÙØªØ±Ø§Øª Ø§Ù„ØªÙ‚Ù„Ø¨ Ø§Ù„Ø¹Ø§Ù„ÙŠ
        4. ØªØ­Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¹Ø·Ù„Ø§Øª ÙˆØ§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©

        Returns:
            dict: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ
        """
        try:
            if 'timestamp' not in data.columns:
                data['timestamp'] = data.index

            # 1. ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø³Ø§Ø¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…
            data['hour'] = data['timestamp'].dt.hour
            hourly = data.groupby('hour').agg({
                'target': ['mean', 'count'],
                'rsi': 'mean',
                'volume': 'mean'
            })

            # 2. ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø£ÙŠØ§Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹
            data['weekday'] = data['timestamp'].dt.weekday
            weekday = data.groupby('weekday').agg({
                'target': ['mean', 'count'],
                'rsi': 'mean',
                'volume': 'mean'
            })

            # 3. ØªØ­Ø¯ÙŠØ¯ ÙØªØ±Ø§Øª Ø§Ù„ØªÙ‚Ù„Ø¨ Ø§Ù„Ø¹Ø§Ù„ÙŠ
            data['volatility'] = data['high'] - data['low']
            volatile_hours = data.groupby('hour')['volatility'].mean().nlargest(3).index.tolist()

            # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø·Ù„Ø§Øª
            holiday_analysis = self._analyze_holiday_performance(data)

            return {
                'best_hours': hourly['target']['mean'].nlargest(3).index.tolist(),
                'worst_hours': hourly['target']['mean'].nsmallest(3).index.tolist(),
                'best_weekdays': weekday['target']['mean'].nlargest(3).index.tolist(),
                'volatile_hours': volatile_hours,
                'holiday_effect': holiday_analysis,
                'hourly_stats': hourly.to_dict(),
                'weekday_stats': weekday.to_dict()
            }

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø³ÙˆÙ‚: %s", str(e), exc_info=True)
            return {'error': str(e)}

    def _analyze_holiday_performance(self, data: pd.DataFrame) -> dict:
        """
        ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø®Ù„Ø§Ù„ Ø§Ù„Ø¹Ø·Ù„Ø§Øª ÙˆØ§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©

        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        1. Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø¨Ù„Ø¯Ø§Ù†
        2. ØªØ­Ù„ÙŠÙ„ Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù‡Ø§Ù…Ø©
        3. ØªÙƒØ§Ù…Ù„ Ù…Ø¹ ØªÙ‚ÙˆÙŠÙ…Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©
        """
        try:
            # 1. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø·Ù„Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            us_holidays = holidays.US()
            uk_holidays = holidays.UK()

            # 2. ØªØµÙ†ÙŠÙ Ø§Ù„Ø£ÙŠØ§Ù…
            data['is_holiday'] = data['timestamp'].apply(
                lambda x: x in us_holidays or x in uk_holidays
            )

            # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
            holiday_stats = data.groupby('is_holiday')['target'].agg(['mean', 'count'])

            # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© (ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ù‡Ù†Ø§)
            event_dates = self._get_economic_events(data['timestamp'].min(), data['timestamp'].max())
            data['is_event_day'] = data['timestamp'].isin(event_dates)
            event_stats = data.groupby('is_event_day')['target'].agg(['mean', 'count'])

            return {
                'holiday_performance': holiday_stats.to_dict(),
                'event_performance': event_stats.to_dict(),
                'recommendation': "ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø®Ù„Ø§Ù„ Ø§Ù„Ø¹Ø·Ù„Ø§Øª" if holiday_stats.loc[True, 'mean'] < 0.5 else "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ø«ÙŠØ± Ø³Ù„Ø¨ÙŠ Ù„Ù„Ø¹Ø·Ù„Ø§Øª"
            }

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø·Ù„Ø§Øª: %s", str(e), exc_info=True)
            return {'error': str(e)}

    def auto_optimize_strategy(self, symbol: str):
        """
        Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ†:
        1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±
        2. ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø³ÙˆÙ‚
        3. Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙƒÙŠÙÙŠ

        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        - Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
        - Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø¸Ø±ÙˆÙ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…ØªØºÙŠØ±Ø©
        """
        try:
            # 1. Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø©
            self.update_training_data(symbol)

            # 2. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±
            optimization_results = self.optimize_entry_conditions(symbol)

            # 3. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            model = self.train_ml_model(symbol)

            # 4. ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            performance = self.evaluate_model_performance(model, symbol)

            # 5. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¬ÙŠØ¯Ø©
            if performance.get('profit_factor', 0) > 1.5:
                self.apply_new_parameters(symbol, optimization_results)
                return {
                    'status': 'success',
                    'optimized_params': optimization_results,
                    'model_performance': performance
                }
            else:
                return {
                    'status': 'no_improvement',
                    'message': 'Ù„Ù… ÙŠØªÙ… ØªØ­Ù‚ÙŠÙ‚ ØªØ­Ø³Ù† ÙƒØ§ÙÙŠ'
                }

        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: %s", str(e), exc_info=True)
            return {'status': 'error', 'message': str(e)}

    def save_optimization_results(self, symbol: str, results: dict):
        """
        Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± ÙÙŠ Ù…Ù„Ù JSON
        """
        try:
            os.makedirs('optimization_results', exist_ok=True)
            file_path = f'optimization_results/{symbol}_{datetime.now().strftime("%Y%m%d")}.json'
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'symbol': symbol,
                    'timestamp': datetime.now().isoformat(),
                    'results': results
                }, f, indent=2, ensure_ascii=False)
                
            self.logger.info("ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ø³ÙŠÙ† %s ÙÙŠ %s", symbol, file_path)
            
        except Exception as e:
            self.logger.error("ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†: %s", str(e), exc_info=True)

    def _process_coin_with_strategy(self, symbol: str, aggressive: bool = False):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù…Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"""
        if aggressive:
            self._process_coin_aggressive(symbol)
        else:
            self._process_coin_conservative(symbol)

    def analyze_market_timing(self):
        """ØªØ­Ù„ÙŠÙ„ ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø«Ù„ ÙˆØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        analysis = {}
        for symbol in self.symbols:
            data = self.get_historical_data(symbol, '1h', days=30)
            if data is not None:
                analysis[symbol] = self._analyze_optimal_times(data)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø«Ù„Ù‰ Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ù…ÙˆØ²
        all_hours = []
        for symbol_analysis in analysis.values():
            all_hours.extend(symbol_analysis.get('best_hours', []))
        
        self.optimal_trading_hours = list(set(all_hours))  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        
        self.save_market_timing_analysis(analysis)
        
    @staticmethod
    def _validate_indicators(df):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©"""
        required_indicators = ['ema20', 'ema50', 'rsi']
        for indicator in required_indicators:
            if indicator not in df.columns:
                raise ValueError(f"Ø§Ù„Ù…Ø¤Ø´Ø± {indicator} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            if df[indicator].isnull().any():
                raise ValueError(f"ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ù…Ø¤Ø´Ø± {indicator}")

    def get_account_balance(self):
        def fetch_balance():
            return self.client.get_account()
        
        try:
            return self.safe_api_request(
                fetch_balance,
                
                rate_limit=0.5  # Ø·Ù„Ø¨ÙŠÙ† ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
            )
        except Exception as e:
                 self.send_notification('error', f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø±ØµÙŠØ¯: {str(e)}")
                 return None

    @staticmethod
    def generate_recommendations(results: dict) -> list:
        """
        ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - ØªØ­Ù„ÙŠÙ„ Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        - Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø°ÙƒÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
        - Ø¯Ø¹Ù… Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©
        """
        recs = []

        if results.get('win_rate', 0) < 0.6:
            recs.append("Ø²ÙŠØ§Ø¯Ø© Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¯Ø®ÙˆÙ„ (Ù…Ø«Ù„ Ø±ÙØ¹ Ø­Ø¯ RSI Ø§Ù„Ø£Ø¯Ù†Ù‰)")

        if results.get('avg_duration', 0) > 180:
            recs.append("ØªØ´Ø¯ÙŠØ¯ Ø´Ø±ÙˆØ· Ø§Ù„Ø®Ø±ÙˆØ¬ Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¯Ø© Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ØµÙÙ‚Ø§Øª")

        if results.get('max_loss', 0) < -8:
            recs.append("Ø¥Ø¶Ø§ÙØ© Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…ØªØ­Ø±Ùƒ")

        return recs if recs else ["Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ§Øª - Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯"]

    def get_optimization_report(self, symbol: str) -> str:
        """
        Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø¹Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬ backtesting Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
        - ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù…Ù†Ø³Ù‚ Ø¨Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø©
        - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        """
        try:
            params = self.load_optimized_params(symbol)
            if not params:
                return f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ØªØ­Ø³ÙŠÙ† Ù„Ù€ {symbol}"
                
            backtest = self.backtest_strategy(symbol)
            analysis = self.analyze_backtest_results(backtest)
            
            report = (
                f"ğŸ“Š ØªÙ‚Ø±ÙŠØ± ØªØ­Ø³ÙŠÙ† {symbol}\n"
                f"ğŸ“… Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: {params.get('last_updated', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}\n"
                f"ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {analysis['overall'].get('win_rate', 0) * 100:.1f}%\n"
                f"ğŸ’° Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø¨Ø­: {analysis['overall'].get('avg_profit', 0):.2f}%\n"
                f"ğŸ” Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª: {analysis['overall'].get('total_trades', 0)}\n"
                f"ğŸ•’ Ø£ÙØ¶Ù„ ÙˆÙ‚Øª Ù„Ù„ØªØ¯Ø§ÙˆÙ„: {max(analysis['hourly_analysis'].items(), key=lambda x: x[1]['avg_profit'])[0]}:00\n"
                f"ğŸ“Œ Ø§Ù„ØªÙˆØµÙŠØ§Øª:\n- " + "\n- ".join(analysis.get('recommendations', ['Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ§Øª']))
            )
            
            return report
            
        except Exception as e:
            return f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"

    def analyze_backtest_results(self, results: dict) -> dict:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        """
        if 'error' in results:
            return results

        try:
            trades = results['trades']

            # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ‚Øª Ù…Ù† Ø§Ù„ÙŠÙˆÙ…
            hour_groups = {h: [] for h in range(24)}
            for trade in trades:
                hour = trade['entry_time'].hour
                hour_groups[hour].append(trade['profit_pct'])

            hour_analysis = {
                h: {
                    'avg_profit': sum(profts)/len(profts) if profts else 0,
                    'win_rate': len([p for p in profts if p > 0])/len(profts) if profts else 0,
                    'trade_count': len(profts)
                }
                for h, profts in hour_groups.items()
            }

            # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ ÙŠÙˆÙ… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹
            weekday_groups = {d: [] for d in range(7)}
            for trade in trades:
                weekday = trade['entry_time'].weekday()
                weekday_groups[weekday].append(trade['profit_pct'])

            weekday_analysis = {
                d: {
                    'avg_profit': sum(profts)/len(profts) if profts else 0,
                    'win_rate': len([p for p in profts if p > 0])/len(profts) if profts else 0,
                    'trade_count': len(profts)
                }
                for d, profts in weekday_groups.items()
            }

            return {
                'overall': results,
                'hourly_analysis': hour_analysis,
                'weekday_analysis': weekday_analysis,
                'recommendations': self.generate_recommendations(results)
            }

        except Exception as e:
            return {'error': f'ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {str(e)}'}

    def execute_buy_order(self, symbol):
        """
        ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø´Ø±Ø§Ø¡ Ø°ÙƒÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†:
        - Ø«Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        - Ù…Ø¹Ù†ÙˆÙŠØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
        - Ø¥Ø´Ø§Ø±Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©
        - Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø±ÙƒØ² Ø­Ø§Ù„ÙŠ
        """
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø±ÙƒØ² Ø­Ø§Ù„ÙŠ
            if symbol in self.current_positions:
                self.logger.info("ğŸš« ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø´Ø±Ø§Ø¡ Ù„Ù€ %s Ù„Ø£Ù† Ù…Ø±ÙƒØ²Ù‹Ø§ Ù…ÙØªÙˆØ­Ù‹Ø§ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§.", symbol)
                return None

            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø´Ø§Ø±Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©
            sentiment_score = self.news_sentiment.get(symbol, {}).get("score", 0)
            pro_signals_count = len(self.pro_signals.get(symbol, []))

            if sentiment_score <= 0.1:
                self.logger.warning("ğŸ“‰ Ù…Ø¹Ù†ÙˆÙŠØ§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø³Ù„Ø¨ÙŠØ© Ù„Ù€ %s: %s", symbol, sentiment_score)
                return None

            if pro_signals_count < 2:
                self.logger.warning("ğŸ“‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù‚Ù„ÙŠÙ„ Ù„Ù€ %s: %s", symbol, pro_signals_count)
                return None

            # 3. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤
            model = self.models.get(symbol)
            if not model:
                self.logger.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ§Ø­ Ù„Ù€ %s", symbol)
                return None

            input_data = pd.DataFrame([[
                0, 0, 50, 0, 1000000,
                sentiment_score, pro_signals_count
            ]], columns=[
                'ema20', 'ema50', 'rsi', 'macd',
                'volume', 'news_sentiment', 'signal_count'
            ])

            prediction = model.predict(input_data)
            confidence = None

            if hasattr(model, "predict_proba"):
                probabilities = model.predict_proba(input_data)
                confidence = probabilities[0][1]

            if prediction[0] != 1 or (confidence is not None and confidence < 0.65):
                self.logger.info("âŒ Ù„Ù… ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ Ø´Ø±Ø· Ø§Ù„Ø´Ø±Ø§Ø¡ Ù„Ù€ %s (Ø§Ù„Ø«Ù‚Ø©: %s)", symbol, confidence)
                return None

            # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…ØªØ§Ø­
            balance = float(self.client.get_asset_balance('USDT')['free'])
            if balance <= 6:
                self.send_notification('warning', f'Ø±ØµÙŠØ¯ ØºÙŠØ± ÙƒØ§ÙÙŠ Ù„Ù€ {symbol}: {balance:.2f} USDT')
                return None

            # 5. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø± ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ©
            ticker = self.client.get_symbol_ticker(symbol=symbol)
            current_price = float(ticker['price'])
            if current_price <= 0:
                raise ValueError(f"Ø³Ø¹Ø± ØºÙŠØ± ØµØ§Ù„Ø­: {current_price}")

            step_size, min_qty = self.get_trade_limits(symbol)
            quantity = (balance * 0.3) / current_price
            quantity = float(np.floor(quantity / step_size) * step_size)

            if quantity <= min_qty:
                error_msg = f'ÙƒÙ…ÙŠØ© ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù€ {symbol}: {quantity:.6f} (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: {min_qty:.6f})'
                self.logger.error(error_msg)
                self.send_notification('error', error_msg)
                return None

            # 6. ØªÙ†ÙÙŠØ° Ø§Ù„Ø´Ø±Ø§Ø¡
            order = self.client.create_order(
                symbol=symbol,
                side=Client.SIDE_BUY,
                type=Client.ORDER_TYPE_MARKET,
                quantity=quantity
            )

            # 7. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø±ÙƒØ²
            self.current_positions[symbol] = {
                'entry_price': current_price,
                'quantity': quantity,
                'timestamp': datetime.now(),
            }

            self.send_notification(
                'buy',
                f"âœ… ØªÙ… Ø§Ù„Ø´Ø±Ø§Ø¡\n"
                f"ğŸª™ {symbol}\n"
                f"ğŸ’° Ø§Ù„Ø³Ø¹Ø±: {current_price:.4f}\n"
                f"ğŸ“Š Ø§Ù„ÙƒÙ…ÙŠØ©: {quantity:.4f}\n"
                f"ğŸ’µ Ø§Ù„Ù‚ÙŠÙ…Ø©: {(quantity*current_price):.2f} USDT"
            )

            return order

        except Exception as e:
            error_msg = f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø´Ø±Ø§Ø¡ Ù„Ù€ {symbol}: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            self.send_notification('error', error_msg)
            return None

    def _process_coin(self, symbol):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„ÙƒÙ„ Ø¹Ù…Ù„Ø© Ù…Ø¹ Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        """
        self.logger.info("Ø¨Ø¯Ø£ Ù…Ø¹Ø§Ù„Ø¬Ø© %s", symbol)
        start_time = time.time()
        processed_successfully = False

        try:
            # ===== 1. ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø¨Ø§Ø± =====
            try:
                self.update_news_sentiment(symbol)
                self.logger.debug("ØªÙ… ØªØ­Ø¯ÙŠØ« Ø£Ø®Ø¨Ø§Ø± %s", symbol)
            except Exception as news_error:
                self.logger.error("Ø£Ø®Ø¨Ø§Ø± %s | %s: %s", symbol, type(news_error).__name__, str(news_error), exc_info=True)
                self.send_notification('warning', f"âš ï¸ Ø£Ø®Ø¨Ø§Ø± {symbol[:4]}...")

            # ===== 2. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© =====
            try:
                signal_count_before = len(self.pro_signals.get(symbol, []))
                self.update_pro_signals(symbol)
                signal_count_after = len(self.pro_signals.get(symbol, []))
                self.logger.debug("Ø¥Ø´Ø§Ø±Ø§Øª %s: %d Ø¬Ø¯ÙŠØ¯Ø©", symbol, signal_count_after - signal_count_before)
            except Exception as signal_error:
                self.logger.error("Ø¥Ø´Ø§Ø±Ø§Øª %s | %s: %s", symbol, type(signal_error).__name__, str(signal_error), exc_info=True)

            # ===== 3. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (5m) =====
            try:
                df_5m = self.get_historical_data(symbol, interval='5m', limit=100)
                if df_5m is None or df_5m.empty:
                    self.logger.error("Ø¨ÙŠØ§Ù†Ø§Øª %s (5m) ÙØ§Ø±ØºØ©", symbol)
                    self.send_notification('warning', f"ğŸ“‰ Ø¨ÙŠØ§Ù†Ø§Øª {symbol[:4]} (5m)...")
                    return
            except Exception as data_error:
                self.logger.critical("Ø¨ÙŠØ§Ù†Ø§Øª %s | %s: %s", symbol, type(data_error).__name__, str(data_error), exc_info=True)
                self.send_notification('error', f"âŒ Ø¨ÙŠØ§Ù†Ø§Øª {symbol[:4]}...")
                return

            # ===== 4. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ (5m) =====
            try:
                df_5m = self.calculate_technical_indicators(df_5m)
                required_indicators = ['ema20', 'ema50', 'rsi', 'macd']
                if not all(col in df_5m.columns for col in required_indicators):
                    missing = [col for col in required_indicators if col not in df_5m.columns]
                    raise ValueError(f"Ù…Ø¤Ø´Ø±Ø§Øª ÙÙ†ÙŠØ© Ù†Ø§Ù‚ØµØ©: {missing}")

                self.logger.debug(
                    "ØªØ­Ù„ÙŠÙ„ %s (5m): EMA20=%.4f, RSI=%.2f",
                    symbol,
                    df_5m['ema20'].iloc[-1],
                    df_5m['rsi'].iloc[-1]
                )
            except Exception as ta_error:
                self.logger.error("ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ %s | %s: %s", symbol, type(ta_error).__name__, str(ta_error), exc_info=True)
                self.send_notification('error', f"ğŸ“Š ØªØ­Ù„ÙŠÙ„ {symbol[:4]}...")
                return

            # ===== 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰ =====
            timeframe_analysis = {}
            try:
                timeframe_analysis = self.analyze_multiple_timeframes(symbol)
                if not timeframe_analysis:
                    self.logger.warning("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù€ %s Ù„Ù… ÙŠØ¹Ø· Ù†ØªØ§Ø¦Ø¬", symbol)
            except Exception as timeframe_error:
                self.logger.error("Ø£Ø·Ø± Ø²Ù…Ù†ÙŠØ© %s | %s: %s", symbol, type(timeframe_error).__name__, str(timeframe_error), exc_info=True)

            # ===== 6. ØªÙ‚ÙŠÙŠÙ… Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ =====
            try:
                if self.evaluate_entry_conditions(df_5m, symbol):
                    self.logger.info("Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ù„Ù€ %s Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø±", symbol)

                    # ===== 7. ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø§Ù„Ø´Ø±Ø§Ø¡ =====
                    try:
                        order_result = self.execute_buy_order(symbol)
                        if order_result:
                            self.logger.info("ØªÙ… ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø´Ø±Ø§Ø¡ %s", symbol)
                            processed_successfully = True
                        else:
                            self.logger.warning("ÙØ´Ù„ ØªÙ†ÙÙŠØ° Ø´Ø±Ø§Ø¡ %s", symbol)
                    except Exception as order_error:
                        self.logger.error("ØªÙ†ÙÙŠØ° Ø£Ù…Ø± %s | %s: %s", symbol, type(order_error).__name__, str(order_error), exc_info=True)
                        self.send_notification('error', f"ğŸ’¸ ØªÙ†ÙÙŠØ° {symbol[:4]}...")
            except Exception as evaluation_error:
                self.logger.error("ØªÙ‚ÙŠÙŠÙ… %s | %s: %s", symbol, type(evaluation_error).__name__, str(evaluation_error), exc_info=True)

        except Exception as global_error:
            self.logger.critical("ÙØ´Ù„ Ø¹Ø§Ù… ÙÙŠ %s | %s: %s", symbol, type(global_error).__name__, str(global_error), exc_info=True)
            self.send_notification(
                'error',
                f"â›” ÙØ´Ù„ ÙÙŠ {symbol[:4]}\n"
                f"ğŸ“› {type(global_error).__name__}\n"
                f"â³ {datetime.now().strftime('%H:%M')}"
            )
        finally:
            exec_time = time.time() - start_time
            status = "Ø¨Ù†Ø¬Ø§Ø­" if processed_successfully else "Ø¨ÙØ´Ù„"
            self.logger.info("Ø§Ù†ØªÙ‡Øª Ù…Ø¹Ø§Ù„Ø¬Ø© %s %s ÙÙŠ %.2f Ø«Ø§Ù†ÙŠØ©", symbol, status, exec_time)

    def manage_all_positions(self):
        """
        Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© Ø§Ù„ØªÙŠ ØªØ¨ÙŠØ¹ ÙÙ‚Ø· Ø¹Ù†Ø¯:
        1. ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø£Ø¯Ù†Ù‰ (min_profit) 
        2. Ù„Ù…Ø³ Ø³Ø¹Ø± Ø§Ù„ØªØ±ÙŠÙ„ÙŠÙ†Øº Ø³ØªÙˆØ¨
        Ù…Ø¹Ù‹Ø§!
        """
        if not self.current_positions:
            return

        for symbol, position in self.current_positions.items():
            if not position:
                continue

            try:
                # 1. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                ticker = self.client.get_symbol_ticker(symbol=symbol)
                current_price = float(ticker['price'])
                entry_price = position['entry_price']
                profit_percent = (current_price - entry_price) / entry_price * 100

                # 2. ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ±ÙŠÙ„ÙŠÙ†Øº Ø³ØªÙˆØ¨ ÙÙ‚Ø· Ø¥Ø°Ø§ Ø­Ù‚Ù‚Ù†Ø§ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø£Ø¯Ù†Ù‰
                if profit_percent >= self.min_profit:
                    new_stop = current_price * (1 - self.trailing_percent / 100)
                    if symbol not in self.trailing_stops or new_stop > self.trailing_stops[symbol]:
                        self.trailing_stops[symbol] = new_stop
                        self.logger.debug("Updated trailing for %s: %.4f", symbol, new_stop)

                # 3. Ø§Ù„Ø¨ÙŠØ¹ ÙÙ‚Ø· Ø¥Ø°Ø§ ØªØ­Ù‚Ù‚ Ø§Ù„Ø´Ø±Ø·Ø§Ù† Ù…Ø¹Ù‹Ø§
                if (profit_percent >= self.min_profit and 
                    symbol in self.trailing_stops and 
                    current_price < self.trailing_stops[symbol]):
                    
                    duration = datetime.now() - position['timestamp']
                    self._execute_sell_order(
                        symbol=symbol,
                        price=current_price,
                        position=position,
                        profit=profit_percent,
                        duration=duration,
                        
                    )

            except binance.exceptions.BinanceAPIException as e:
                error_msg = f"Binance error for {symbol}: {e.status_code}"
                self.logger.error(error_msg)
                self.send_notification('error', error_msg[:200])

            except Exception as e:
                error_msg = f"Error managing {symbol}: {str(e)}"
                self.logger.error(error_msg, exc_info=True)
                self.send_notification('error', error_msg[:200])

    def _execute_sell_order(self, symbol, price, position, profit, duration):
        """
        ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø¨ÙŠØ¹ Ø¢Ù…Ù† Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ ÙƒØ§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Parameters:
            symbol (str): Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„ BTCUSDT)
            price (float): Ø³Ø¹Ø± Ø§Ù„Ø¨ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ
            position (dict): ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ù…ÙØªÙˆØ­
            profit (float): Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©
            duration (timedelta): Ù…Ø¯Ø© Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ØµÙÙ‚Ø©

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£Ù…Ø± Ù…Ù† Ø§Ù„Ø¨ÙˆØ±ØµØ©

        Raises:
            Exception: Ø¥Ø°Ø§ ÙØ´Ù„ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±
        """
        try:
            # 1. ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø§Ù„Ø¨ÙŠØ¹
            order = self.client.create_order(
                symbol=symbol,
                side=Client.SIDE_SELL,
                type=Client.ORDER_TYPE_MARKET,
                quantity=position['quantity']
            )

            # 2. Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ø¨ÙŠØ¹
            self.send_notification('sell', {
                'symbol': symbol,
                'quantity': position['quantity'],
                'price': price,
                'profit': f"{profit:.2f}%",
                'duration': str(duration),
                'entry_price': position['entry_price']
            })

            # 3. ØªÙ†Ø¸ÙŠÙ ÙƒØ§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
            with self.lock:  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙÙ„ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠØ©
                # Ø£. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ù…ÙØªÙˆØ­
                if symbol in self.current_positions:
                    del self.current_positions[symbol]

                # Ø¨. Ø¥Ø²Ø§Ù„Ø© ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹
                self.trailing_stops.pop(symbol, None)

                # Ø¬. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚Ù…Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© (Ø§Ù„Ù…Ø¶Ø§ÙØ© Ù…Ù†Ùƒ)
                if symbol in self.last_peaks:
                    del self.last_peaks[symbol]

                # Ø¯. Ø¥Ø²Ø§Ù„Ø© Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø¥Ù† ÙˆØ¬Ø¯Øª
                if symbol in self.fib_levels:
                    del self.fib_levels[symbol]

                # Ù‡Ù€. Ø¥Ø²Ø§Ù„Ø© Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠÙÙˆØª Ø¥Ù† ÙˆØ¬Ø¯Øª
                if symbol in self.pivot_points:
                    del self.pivot_points[symbol]

            return order

        except Exception as e:
            error_msg = f"ÙØ´Ù„ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨ÙŠØ¹ Ù„Ù€ {symbol}: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            self.send_notification('error', error_msg)
            raise
            
    def _calculate_fibonacci_levels(self, df):
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©"""
        try:
            high = df['high'].max()
            low = df['low'].min()

            if pd.isna(high) or pd.isna(low):
                raise ValueError("Ù‚ÙŠÙ… high/low ØºÙŠØ± ØµØ§Ù„Ø­Ø©")

            diff = high - low
            if diff <= 0:
                raise ValueError("ÙØ±Ù‚ ØºÙŠØ± ØµØ§Ù„Ø­ Ø¨ÙŠÙ† high Ùˆ low")

            self.fib_levels = {
                '38.2%': high - diff * 0.382,
                '50%': high - diff * 0.5,
                '61.8%': high - diff * 0.618
            }

        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ: %s", str(e))
            self.fib_levels = {}

    def _calculate_pivot_points(self, df):
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠÙÙˆØª Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©"""
        try:
            if len(df) < 1:
                raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¨ÙŠÙÙˆØª")

            day_df = df.resample('1D').agg({
                'high': 'max',
                'low': 'min',
                'close': 'last'
            }).dropna()

            if len(day_df) < 1:
                raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙŠÙˆÙ…ÙŠØ© ÙƒØ§ÙÙŠØ©")

            pivot = (day_df['high'] + day_df['low'] + day_df['close']) / 3
            self.pivot_points = {
                'pivot': pivot.iloc[-1],
                'R1': (2 * pivot - day_df['low']).iloc[-1],
                'S1': (2 * pivot - day_df['high']).iloc[-1]
            }

        except Exception as e:
            self.logger.error("ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠÙÙˆØª: %s", str(e))
            self.pivot_points = {}

    # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ±ÙŠÙ„ÙŠÙ†Øº Ø³ØªÙˆØ¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    def update_trailing_stop(self, symbol, current_price):
        """
        ØªØ­Ø¯ÙŠØ« Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ±ÙŠÙ„ÙŠÙ†Øº Ø³ØªÙˆØ¨ Ù„Ø¹Ù…Ù„Ø© Ù…Ø¹ÙŠÙ†Ø© Ø­Ø³Ø¨ Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø± (last_peak) ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù‡.
        """
        if symbol not in self.last_peaks or current_price > self.last_peaks[symbol]:
            self.last_peaks[symbol] = current_price

        trailing_stop = self.last_peaks[symbol] * (1 - self.trailing_percent / 100)
        self.trailing_stops[symbol] = trailing_stop
        return trailing_stop

    def evaluate_entry_conditions(self, df, symbol):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        
        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        - ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© (5m, 15m, 1h)
        - Ù…Ø¹Ø§ÙŠÙŠØ± Ø¯Ø®ÙˆÙ„ Ù…Ø­Ø³Ù†Ø© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ backtesting
        - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        - ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        
        Args:
            df: DataFrame ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ 5m
            symbol: Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡Ø§
            
        Returns:
            bool: True Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ØŒ False Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ±
        """
        try:
            # ===== 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© =====
            if df is None or len(df) == 0:
                self.logger.warning("Ø¨ÙŠØ§Ù†Ø§Øª %s ÙØ§Ø±ØºØ© Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­Ø©", symbol)
                return False

            required_columns = ['ema20', 'ema50', 'rsi', 'macd', 'volume', 'close']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                self.logger.warning("Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù€ %s: %s", symbol, missing_columns)
                return False

            df_clean = df.dropna(subset=required_columns)
            if df_clean.empty:
                self.logger.warning("Ø¨ÙŠØ§Ù†Ø§Øª %s ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ", symbol)
                return False

            last = df_clean.iloc[-1]
            
            # ===== 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø© =====
            optimized_params = self.load_optimized_params(symbol)
            params = {
                'rsi_min': optimized_params.get('rsi_min', 50),
                'ema_cross': optimized_params.get('ema_cross', True),
                'macd_condition': optimized_params.get('macd_condition', True),
                'news_threshold': optimized_params.get('news_threshold', 0.2),
                'min_signals': optimized_params.get('min_signals', 1)
            }

            # ===== 3. ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© =====
            timeframe_analysis = {}
            try:
                timeframe_analysis = self.analyze_multiple_timeframes(symbol)
                if not timeframe_analysis:
                    self.logger.warning("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù€ %s", symbol)
                    return False
            except Exception as e:
                self.logger.error("Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù€ %s: %s", symbol, str(e))
                return False

            # ===== 4. ØªØ·Ø¨ÙŠÙ‚ Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ =====
            cond_5m = (
                (not params['ema_cross'] or (last['ema20'] > last['ema50'])) and
                (last['rsi'] > params['rsi_min']) and
                (not params['macd_condition'] or (last['macd'] > last['macd_signal']))
            )

            cond_15m = False
            if '15m' in timeframe_analysis:
                try:
                    tf15 = timeframe_analysis['15m']
                    cond_15m = (
                        (tf15['ema20'] > tf15['ema50']) and
                        (tf15['rsi'] > params['rsi_min'])
                    )
                except KeyError as e:
                    self.logger.warning("Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø·Ø§Ø± 15m Ù†Ø§Ù‚ØµØ© Ù„Ù€ %s: %s", symbol, str(e))
                    cond_15m = False

            cond_1h = False
            if '1h' in timeframe_analysis:
                try:
                    tf1h = timeframe_analysis['1h']
                    cond_1h = (tf1h['ema20'] > tf1h['ema50'])
                except KeyError as e:
                    self.logger.warning("Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø·Ø§Ø± 1h Ù†Ø§Ù‚ØµØ© Ù„Ù€ %s: %s", symbol, str(e))
                    cond_1h = False

            try:
                news_score = self.news_sentiment.get(symbol, {}).get('score', 0)
                signal_count = len(self.pro_signals.get(symbol, []))
                cond_sentiment = (news_score > params['news_threshold']) and \
                                (signal_count >= params['min_signals'])
            except Exception as e:
                self.logger.error("Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù€ %s: %s", symbol, str(e))
                cond_sentiment = False

            final_condition = (
                cond_5m and 
                cond_15m and 
                cond_1h and 
                cond_sentiment
            )

            # ===== 6. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ML =====
            if final_condition:
                try:
                    features = [[
                        last['ema20'], last['ema50'], last['rsi'],
                        last['macd'], last['volume'], 
                        news_score, signal_count
                    ]]

                    model = self.load_or_initialize_model(symbol)
                    if model is None:
                        self.logger.warning("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ØªØ§Ø­ Ù„Ù€ %s", symbol)
                        return False

                    input_data = pd.DataFrame(features, columns=[
                        'ema20', 'ema50', 'rsi', 'macd',
                        'volume', 'news_sentiment', 'signal_count'
                    ])

                    prediction = self.safe_model_prediction(model, input_data)
                    return prediction[0] == 1 if prediction is not None else False

                except Exception as e:
                    self.logger.error("ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù€ %s: %s", symbol, str(e))
                    return False

            return False

        except Exception as e:
            self.logger.critical("ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø´Ø±ÙˆØ· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù€ %s: %s", symbol, str(e), exc_info=True)
            return False

    def load_or_initialize_model(self, symbol, use_cache=True):
        """
        Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© ØªÙ…Ø§Ù…Ø§Ù‹ Ù…Ø¹:
        - Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù„Ù
        - Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¨Ù„ Ø§Ù„ØªØ³Ù„ÙŠÙ…
        - Ù†Ø¸Ø§Ù… Ø·ÙˆØ§Ø±Ø¦ Ù…ØªÙƒØ§Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
        - Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        """
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            models_dir = 'models'
            if not os.path.exists(models_dir):
                os.makedirs(models_dir)
                self.logger.warning("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¬Ø¯ÙŠØ¯Ù‹Ø§ Ù„Ù€ %s", symbol)

            model_path = os.path.join(models_dir, f'xgb_model_{symbol}.pkl')

            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø£ÙˆÙ„Ø§Ù‹
            if use_cache and hasattr(self, '_model_cache') and symbol in self._model_cache:
                cached_model = self._model_cache[symbol]
                if self._validate_model(cached_model):
                    return cached_model

            # 3. Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            if os.path.exists(model_path):
                try:
                    with open(model_path, 'rb') as f:
                        model = joblib.load(f)

                    if self._validate_model(model):
                        test_result = self._test_model_performance(model)
                        if test_result['success']:
                            if use_cache:
                                self._add_to_cache(symbol, model)
                            return model
                        else:
                            self.logger.warning("Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ØºÙŠØ± Ù…Ù‚Ø¨ÙˆÙ„ Ù„Ù€ %s: %s",
                                                 symbol, test_result['message'])
                except Exception as load_error:
                    self.logger.error("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù€ %s: %s",
                                      symbol, str(load_error), exc_info=True)

            # 4. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£ÙˆÙ„)
            try:
                emergency_model = self._create_emergency_model()
                if self._validate_model(emergency_model):
                    test_result = self._test_model_performance(emergency_model)
                    if test_result['success']:
                        self.logger.warning("ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1) Ù„Ù€ %s", symbol)
                        self.send_notification('warning',
                                               f"âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ (L1) Ù„Ù€ {symbol}")
                        if use_cache:
                            self._add_to_cache(symbol, emergency_model)
                        return emergency_model
            except Exception as emergency_error:
                self.logger.error("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø·ÙˆØ§Ø±Ø¦ (L1) Ù„Ù€ %s: %s",
                                  symbol, str(emergency_error), exc_info=True)

            # 5. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ø¨Ø³ÙŠØ· (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ø§Ù†ÙŠ)
            try:
                fallback_model = self.initialize_fallback_model()
                if self._validate_model(fallback_model):
                    self.logger.critical("ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ø¨Ø³ÙŠØ· (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2) Ù„Ù€ %s", symbol)
                    self.send_notification('error',
                                           f"ğŸš¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ø¨Ø³ÙŠØ· (L2) Ù„Ù€ {symbol}")
                    if use_cache:
                        self._add_to_cache(symbol, fallback_model)
                    return fallback_model
            except Exception as fallback_error:
                self.logger.critical("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙŠÙ„ Ù„Ù€ %s: %s",
                                     symbol, str(fallback_error), exc_info=True)

            # 6. Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡
            raise RuntimeError(f"ÙØ´Ù„ Ø­Ø±Ø¬: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ ØµØ§Ù„Ø­ Ù„Ù€ {symbol}")

        except Exception as e:
            self.logger.critical("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„/ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ %s: %s",
                                 symbol, str(e), exc_info=True)
            self.send_notification('error',
                                   f"ğŸ’¥ ÙØ´Ù„ Ø­Ø±Ø¬ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}\n"
                                   f"ğŸ“› {type(e).__name__}: {str(e)[:200]}")
            raise RuntimeError(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¨Ø¯ÙˆÙ† Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}") from e

    def _add_to_cache(self, symbol, model):
        """Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù…Ø¹ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø­Ø¬Ù…"""
        if not hasattr(self, '_model_cache'):
            self._model_cache = OrderedDict()
            self._max_cached_models = 3

        self._model_cache[symbol] = model
        self._clean_model_cache()

    def _validate_model(self, model):
        """Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        required_methods = ['predict', 'predict_proba', 'fit']
        for method in required_methods:
            if not hasattr(model, method):
                self.logger.error("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙØªÙ‚Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø§Ù„Ø©: %s", method)
                return False

        # ØªØ­Ù‚Ù‚ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ù†ÙˆØ¹ Pipeline
        if hasattr(model, 'steps'):
            last_step = model.steps[-1][1]
            if not hasattr(last_step, 'feature_importances_'):
                self.logger.warning("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ÙˆØ¹ XGBClassifier")
                # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¥Ø´Ø¹Ø§Ø± Ù‡Ù†Ø§ Ø¥Ù† Ø£Ø±Ø¯Øª

        return True

    @staticmethod
    def _test_model_performance(model):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±ÙŠØ©"""
        try:
            rng = np.random.default_rng(42)  # âœ… ØªØ¹ÙŠÙŠÙ† seed Ø«Ø§Ø¨Øª Ù„Ø¶Ù…Ø§Ù† ØªÙƒØ±Ø§Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            test_data = pd.DataFrame(
                rng.random((5, 7)),  # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
                columns=[
                    'ema20', 'ema50', 'rsi', 'macd',
                    'volume', 'news_sentiment', 'signal_count'
                ]
            )

            # Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            predictions = model.predict(test_data)
            if predictions is None or len(predictions) != 5:
                return {
                    'success': False,
                    'message': "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª"
                }

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ØµØ§Ù„Ø­Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
            if hasattr(model, 'predict_proba'):
                probas = model.predict_proba(test_data)
                if probas is None or not np.all(np.isfinite(probas)):
                    return {
                        'success': False,
                        'message': "Ù‚ÙŠÙ… Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© ØºÙŠØ± ØµØ§Ù„Ø­Ø©"
                    }

            return {'success': True, 'message': "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØµØ§Ù„Ø­"}

        except Exception as e:
            return {
                'success': False,
                'message': f"ÙØ´Ù„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡: {str(e)}"
            }

    def monitor_model_performance(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ"""
        for symbol, model in self.models.items():
            try:
                # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø¯ÙŠØ«Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
                recent_data = self.collect_recent_data(symbol)
                if recent_data is None or recent_data.empty:
                    continue

                # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
                performance = self.evaluate_model(model, recent_data)

                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ ØªØ­Øª Ø¹ØªØ¨Ø© Ù…Ø¹ÙŠÙ†Ø©ØŒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                if performance['accuracy'] < 0.6:
                    self.logger.warning(
                        "Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ %s Ù…Ù†Ø®ÙØ¶ (%.2f)ØŒ Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨",
                        symbol, performance['accuracy']
                    )
                    self.retrain_model(symbol)
            except Exception as e:
                self.logger.error(
                    "ÙØ´Ù„ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ %s: %s",
                    symbol, str(e),
                    exc_info=True
                )

    def initialize_and_train_model(self):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯ ÙˆØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ù† Ø§Ù„ØµÙØ± Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
        """
        model = Pipeline([
            ('scaler', StandardScaler()),
            ('xgb', XGBClassifier(
                objective=self.OBJECTIVE_BINARY,
                learning_rate=0.1,
                max_depth=6,
                n_estimators=200,
                random_state=42
            ))
        ], memory=self.memory)

        data_path = 'training_data.csv'
        if not os.path.exists(data_path):
            error_msg = f"âŒ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ {data_path} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."
            self.send_notification('error', error_msg)
            raise FileNotFoundError(error_msg)

        try:
            self.train_ml_model(model)
            return model
        except Exception as e:
            self.send_notification('error', f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {e}")
            raise

    def update_training_data(self, symbol, days=90, interval='1h', profit_threshold=0.3):
        """
        Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ø¹Ø±ÙŠØ© ØªØ§Ø±ÙŠØ®ÙŠØ© ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§ Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø·Ø± (Ø¨Ø¯ÙˆÙ† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø±)

        Parameters:
            symbol: Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„ BTCUSDT)
            days: Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            interval: Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            profit_threshold: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù

        Returns:
            None (ÙŠØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù CSV)
        """
        try:
            # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            klines = self.client.get_historical_klines(symbol, interval, f"{days} day ago UTC")
            if not klines:
                self.send_notification('error', f'âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© ÙƒØ§ÙÙŠØ© Ù„Ù€ {symbol}.')
                return

            # 2. Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            df = pd.DataFrame(klines, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'num_trades',
                'taker_buy_base_vol', 'taker_buy_quote_vol', 'ignore'
            ])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            df = df[['open', 'high', 'low', 'close', 'volume']].astype(float)

            # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ù„Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            df['ema20'] = EMAIndicator(df['close'], 20).ema_indicator()
            df['ema50'] = EMAIndicator(df['close'], 50).ema_indicator()
            df['rsi'] = RSIIndicator(df['close'], 14).rsi()
            macd = MACD(df['close'])
            df['macd'] = macd.macd()
            df['macd_signal'] = macd.macd_signal()

            # 4. Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø£Ø·Ø± Ø²Ù…Ù†ÙŠØ© Ø£Ø®Ø±Ù‰
            try:
                # Ø¨ÙŠØ§Ù†Ø§Øª 15m
                df_15m = self.get_historical_data(symbol, interval='15m', limit=len(df))
                if df_15m is not None:
                    df_15m = self.calculate_technical_indicators(df_15m)
                    df['15m_rsi'] = df_15m['rsi']
                    df['15m_ema20'] = df_15m['ema20']

                # Ø¨ÙŠØ§Ù†Ø§Øª 1h
                df_1h = self.get_historical_data(symbol, interval='1h', limit=len(df))
                if df_1h is not None:
                    df_1h = self.calculate_technical_indicators(df_1h)
                    df['1h_ema50'] = df_1h['ema50']
                    df['1h_volume'] = df_1h['volume']

            except Exception as e:
                self.logger.warning("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©: %s", str(e))

            # 5. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø¯Ù (Target)
            future_window = 12
            future_price = df['close'].shift(-future_window)
            df['target'] = ((future_price - df['close']) / df['close'] * 100 >= profit_threshold).astype(int)

            # 6. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§
            df.dropna(inplace=True)
            file_path = f"training_data_{symbol}.csv"
            df.to_csv(file_path, index=True)

            self.send_notification('update', f'âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {symbol} ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ {file_path}.')

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: %s", str(e), exc_info=True)
            self.send_notification('error', f'âŒ ÙØ´Ù„ ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {symbol}: {e}')

    def compare_models(self, new_model, current_model, X_test, y_test):
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        new_metrics = self.evaluate_model(new_model, X_test, y_test)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¥Ù† ÙˆØ¬Ø¯)
        current_metrics = self.evaluate_model(current_model, X_test, y_test) if current_model else None
        
        # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        comparison_metrics = {
            'Closed Win Rate': (new_metrics['closed_win_rate'], current_metrics['closed_win_rate'] if current_metrics else 0),
            'Avg Holding Time': (new_metrics['avg_holding_time'], current_metrics['avg_holding_time'] if current_metrics else float('inf')),
            'Open Positions Ratio': (new_metrics['open_positions_ratio'], current_metrics['open_positions_ratio'] if current_metrics else 1),
            'Final Balance': (new_metrics['final_balance'], current_metrics['final_balance'] if current_metrics else 0)
        }
        self.logger.debug("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†:\n%s", comparison_metrics)
        
        # Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±
        if not current_model:
            return True  # Ù‚Ø¨ÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù†Ù…ÙˆØ°Ø¬ Ø­Ø§Ù„
            
        improve_threshold = 1.2  # ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„ Ø¨Ù†Ø³Ø¨Ø© 20% Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
        improvement_score = (
            (new_metrics['closed_win_rate'] / current_metrics['closed_win_rate']) * 0.4 +
            (current_metrics['avg_holding_time'] / new_metrics['avg_holding_time']) * 0.3 +
            (current_metrics['open_positions_ratio'] / new_metrics['open_positions_ratio']) * 0.2 +
            (new_metrics['final_balance'] / current_metrics['final_balance']) * 0.1
        )
        
        return improvement_score >= improve_threshold

    def validate_daily_data(self, symbol):
        try:
            df = self.get_historical_data(symbol, interval='1d', limit=30)
            
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if df.isnull().any().any():
                raise ValueError("ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©")
                
            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…ÙØ§Ø¬Ø¦Ø©
            price_change = df['close'].pct_change().abs()
            if (price_change > 0.15).any():  # ØªØºÙŠØ± Ø£ÙƒØ«Ø± Ù…Ù† 15% ÙÙŠ ÙŠÙˆÙ… ÙˆØ§Ø­Ø¯
                self.logger.warning("ØªÙ‚Ù„Ø¨Ø§Øª ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ© ÙÙŠ %s", symbol)
                
            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„
            volume_change = df['volume'].pct_change().abs()
            if (volume_change > 3).any():  # ØªØºÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¨Ø£ÙƒØ«Ø± Ù…Ù† 300%
                self.logger.warning("Ø­Ø¬Ù… ØªØ¯Ø§ÙˆÙ„ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ %s", symbol)
                
            return True
        except Exception as e:
            self.logger.error("ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª %s: %s", symbol, str(e))
            return False

    def adaptive_training_schedule(self):
        for symbol in self.symbols:
            try:
                df = self.get_historical_data(symbol, interval='1h', limit=24*7)  # Ø£Ø³Ø¨ÙˆØ¹ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
                volatility = df['close'].std() / df['close'].mean()
                
                # ØªØ­Ø¯ÙŠØ¯ ÙˆØªÙŠØ±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                if volatility > 0.05:  # ØªÙ‚Ù„Ø¨Ø§Øª Ø¹Ø§Ù„ÙŠØ©
                    schedule.every(12).hours.do(self.retrain_model, symbol).tag(f'training_{symbol}')
                else:  # ØªÙ‚Ù„Ø¨Ø§Øª Ù…Ù†Ø®ÙØ¶Ø©
                    schedule.every(3).days.do(self.retrain_model, symbol).tag(f'training_{symbol}')
                    
            except Exception as e:
                self.logger.error("ÙØ´Ù„ ÙÙŠ Ø¬Ø¯ÙˆÙ„Ø© ØªØ¯Ø±ÙŠØ¨ %s: %s", symbol, str(e))

    def enhanced_backtesting(self, symbol, model, initial_balance=1000):
        try:
            df = self.get_historical_data(symbol, interval='1h', limit=1000)  # ~40 ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df = self.calculate_technical_indicators(df)
            
            balance = initial_balance
            open_positions = []
            closed_positions = []
            
            for i in range(1, len(df)):
                current_data = df.iloc[i]
                last_data = df.iloc[i-1]
                
                # 1. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø¹Ù†Ø¯ ØªØ­Ù‚ÙŠÙ‚ Ø±Ø¨Ø­ 2%
                for pos in open_positions[:]:
                    if current_data['close'] >= pos['entry_price'] * 1.02:
                        profit = pos['quantity'] * (current_data['close'] - pos['entry_price'])
                        balance += profit
                        closed_positions.append({
                            'entry_price': pos['entry_price'],
                            'exit_price': current_data['close'],
                            'duration': i - pos['entry_index'],
                            'profit': profit
                        })
                        open_positions.remove(pos)
                
                # 2. ÙØªØ­ ØµÙÙ‚Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø´Ø±Ø§Ø¡ Ù‚ÙˆÙŠØ©
                input_data = pd.DataFrame([[ 
                    last_data['ema20'], last_data['ema50'], last_data['rsi'],
                    last_data['macd'], last_data['volume'],
                    self.news_sentiment.get(symbol, {}).get('score', 0),
                    len(self.pro_signals.get(symbol, []))
                ]], columns=['ema20', 'ema50', 'rsi', 'macd', 'volume', 'news_sentiment', 'signal_count'])
                
                if model.predict(input_data)[0] == 1 and balance > 10:
                    quantity = (balance * 0.1) / current_data['close']  # Ø§Ø³ØªØ«Ù…Ø§Ø± 10% Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯
                    open_positions.append({
                        'entry_price': current_data['close'],
                        'quantity': quantity,
                        'entry_index': i
                    })
                    balance -= quantity * current_data['close']
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            win_rate = len([p for p in closed_positions if p['profit'] > 0]) / len(closed_positions) if closed_positions else 0
            avg_holding_time = np.mean([p['duration'] for p in closed_positions]) if closed_positions else 0
            open_ratio = len(open_positions) / (len(closed_positions) + len(open_positions))
            
            return {
                'symbol': symbol,
                'closed_win_rate': win_rate,
                'avg_holding_time': avg_holding_time,
                'open_positions_ratio': open_ratio,
                'final_balance': balance + sum(pos['quantity'] * df.iloc[-1]['close'] for pos in open_positions),
                'total_trades': len(closed_positions) + len(open_positions)
            }
            
        except Exception as e:
            self.logger.error("ÙØ´Ù„ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± %s: %s", symbol, str(e))
            return None

    def validate_system(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡"""
        errors = []
        
        # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ ML
        for symbol in self.symbols:
            model = self.models.get(symbol)
            if not model:
                errors.append(f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„ Ù„Ù€ {symbol}")
                
            # Ø§Ø®ØªØ¨Ø§Ø± ØªÙ†Ø¨Ø¤ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
            try:
                dummy_data = pd.DataFrame([[0]*7], columns=[
                    'ema20', 'ema50', 'rsi', 'macd', 
                    'volume', 'news_sentiment', 'signal_count'
                ])
                model.predict(dummy_data)
            except Exception as e:
                errors.append(f"ÙØ´Ù„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}: {str(e)}")
        
        # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
        news_sources = ['cryptopanic', 'newsapi']  # Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        for source in news_sources:
            if not self.check_news_source(source):
                errors.append(f"Ù…ØµØ¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± {source} ØºÙŠØ± Ù…ØªØ§Ø­")
        
        # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„ API
        try:
            self.client.get_account()
        except Exception as e:
            errors.append(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Binance API: {str(e)}")
        
        if errors:
            self.send_notification(
                'error',
                "âŒ Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…:\n- " + "\n- ".join(errors)
            )
            raise RuntimeError("ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…")

    def train_ml_model(self, symbol):
        """
        ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù…Ø¹ Ø¶Ù…Ø§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø© Ø¶Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        1. ØªØ­Ù‚Ù‚ Ø´Ø§Ù…Ù„ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¢Ù…Ù†Ø© Ù„Ø¬Ù…ÙŠØ¹ Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        3. ØªØ³Ø¬ÙŠÙ„ Ù…ÙØµÙ„ Ù„ÙƒÙ„ Ø®Ø·ÙˆØ©
        4. Ø¥Ø´Ø¹Ø§Ø±Ø§Øª ÙÙˆØ±ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        """
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            training_file = f"training_data_{symbol}.csv"
            if not os.path.exists(training_file):
                error_msg = f"Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ {training_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
                self.logger.error("%s", error_msg)
                self.send_notification(
                    'error',
                    f"ğŸ“ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…ÙÙ‚ÙˆØ¯\n"
                    f"ğŸª™ {symbol}\n"
                    f"â° {datetime.now().strftime('%H:%M')}"
                )
                raise FileNotFoundError(error_msg)

            # 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©
            try:
                df = pd.read_csv(training_file)
                required_columns = [
                    'ema20', 'ema50', 'rsi', 'macd',
                    'volume', 'news_sentiment', 'signal_count', 'target'
                ]
                
                if not all(col in df.columns for col in required_columns):
                    missing = [col for col in required_columns if col not in df.columns]
                    self.logger.error("Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø©: %s", ', '.join(missing))
                    raise ValueError(f"Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø©: {', '.join(missing)}")

                df = df.dropna(subset=required_columns)
                if len(df) < 100:  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ 100 ØµÙ Ù„Ù„ØªØ¯Ø±ÙŠØ¨
                    self.logger.error("Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± ÙƒØ§ÙÙŠØ© (%d ØµÙ ÙÙ‚Ø·)", len(df))
                    raise ValueError(f"Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} ØµÙ ÙÙ‚Ø·)")

            except Exception as load_error:
                self.logger.error("ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | %s: %s", type(load_error).__name__, str(load_error), exc_info=True); raise

            # 3. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            try:
                X = df[required_columns[:-1]]  # Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¹Ø¯Ø§ target
                y = df['target']
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y,
                    test_size=0.2,
                    random_state=42,
                    stratify=y
                )
            except Exception as split_error:
                self.logger.error("ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | %s: %s", type(split_error).__name__, str(split_error), exc_info=True); raise

            # 4. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            try:
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('xgb', XGBClassifier(
                        objective=self.OBJECTIVE_BINARY,
                        learning_rate=0.1,
                        max_depth=6,
                        n_estimators=200,
                        random_state=42,
                        eval_metric='logloss'
                    ))
                ], memory=self.memory)  # â† âœ… Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
                
                model.fit(X_train, y_train)
            except Exception as train_error:
                self.logger.error("ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | %s: %s", type(train_error).__name__, str(train_error), exc_info=True); raise

            # 5. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            try:
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                
                metrics = {
                    'accuracy': round(accuracy, 4),
                    'precision': round(precision, 4),
                    'recall': round(recall, 4),
                    'training_samples': len(X_train),
                    'test_samples': len(X_test)
                }
                
                self.logger.info(
                    "Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ %s | Ø§Ù„Ø¯Ù‚Ø©: %.4f | Ø§Ù„Ø¯Ù‚Ø©: %.4f | Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹: %.4f",
                    symbol, metrics['accuracy'], metrics['precision'], metrics['recall']
                )
            except Exception as eval_error:
                self.logger.error("ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | %s: %s", type(eval_error).__name__, str(eval_error), exc_info=True); raise

            # 6. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            try:
                model_path = f"xgb_model_{symbol}.pkl"
                joblib.dump(model, model_path)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
                if not os.path.exists(model_path):
                    raise RuntimeError("ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ")
                    
                self.logger.info("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ %s", model_path)
                
            except Exception as save_error:
                self.logger.error("Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | %s: %s", type(save_error).__name__, str(save_error), exc_info=True); raise

            # 7. Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¬Ø§Ø­
            self.send_notification(
                'report',
                f"ğŸ¯ ØªÙ… ØªØ¯Ø±ÙŠØ¨ {symbol}\n"
                f"ğŸ“Š Ø§Ù„Ø¯Ù‚Ø©: {metrics['accuracy']}\n"
                f"ğŸ” Ø§Ù„Ø¹ÙŠÙ†Ø§Øª: {metrics['training_samples']} ØªØ¯Ø±ÙŠØ¨\n"
                f"â± {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            )

            return model

        except FileNotFoundError:
            raise  # Ù†Ø¹ÙŠØ¯ Ø±ÙØ¹ Ø§Ù„Ø®Ø·Ø£ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¹Ù„Ù‰

        except Exception as e:
            error_msg = f"ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}: {type(e).__name__}: {str(e)}"
            self.logger.critical("ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ %s: %s: %s", symbol, type(e).__name__, str(e), exc_info=True)
            self.send_notification(
                'error',
                f"âŒ ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ {symbol}\n"
                f"ğŸ“› {type(e).__name__}\n"
                f"â° {datetime.now().strftime('%H:%M')}"
            )
            raise

    def safe_model_prediction(self, model, input_data):
        """ØªÙ†Ø¨Ø¤ Ø¢Ù…Ù† Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† input_data Ù‡Ùˆ DataFrame
            if not isinstance(input_data, pd.DataFrame):
                raise TypeError("ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ DataFrame")
                
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            expected_features = [
                'ema20', 'ema50', 'rsi', 
                'macd', 'volume',
                'news_sentiment', 
                'signal_count'
            ]
            
            missing_features = [f for f in expected_features if f not in input_data.columns]
            if missing_features:
                raise ValueError(f"Ø£Ø¹Ù…Ø¯Ø© Ù…ÙÙ‚ÙˆØ¯Ø©: {missing_features}")
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            return model.predict(input_data[expected_features])
            
        except Exception as e:
            self.send_notification('error', f"ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤: {str(e)}")
            return None

    def record_model_performance(self, model, X, y_true, symbol):
        """ØªØ³Ø¬ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ ÙƒØ§Ù…Ù„Ø©"""
        try:
            y_pred = model.predict(X)
            
            performance_log = {
                "timestamp": datetime.now().isoformat(),
                "symbol": symbol,
                "accuracy": round(accuracy_score(y_true, y_pred), 4),
                "precision": round(precision_score(y_true, y_pred, zero_division=0), 4),
                "recall": round(recall_score(y_true, y_pred, zero_division=0), 4),
                "features": X.columns.tolist(),
                "model_type": str(model.named_steps['xgb'].__class__.__name__)
            }

            # Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ù…Ù„Ù
            log_path = f'model_performance_{symbol}.json'
            with open(log_path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(performance_log) + '\n')

        except Exception as e:
            self.logger.error("ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: %s", str(e))

    def get_bot_status(self):
        return {
            'running': self.is_running,
            'start_time': self.start_time,
            'positions': len([p for p in self.current_positions.values() if p]),
            'errors': self.logger.handlers[0].level == logging.ERROR if self.logger.handlers else False
        }

    def _get_system_info(self):
        try:
            return (
                f"ğŸ–¥ Ø§Ù„Ù†Ø¸Ø§Ù…: {platform.system()} {platform.release()}\n"
                f"â° ÙˆÙ‚Øª Ø§Ù„ØªØ´ØºÙŠÙ„: {datetime.now() - self.start_time if self.start_time else 'N/A'}\n"
                f"ğŸ’¾ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {psutil.virtual_memory().percent}% Ù…Ø³ØªØ®Ø¯Ù…Ø©"
            )
        except Exception:
            return "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©"

    def append_training_data(self, df, target, symbol):
        """Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"""
        try:
            if df is None or df.empty:
                raise ValueError("DataFrame ÙØ§Ø±Øº Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­")
                
            last_row = df.iloc[-1]
            
            required_columns = ['ema20', 'ema50', 'rsi', 'macd', 'volume']
            if not all(col in last_row for col in required_columns):
                raise ValueError("Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙÙ‚ÙˆØ¯Ø©")
                
            new_data = {
                'timestamp': datetime.now(timezone.utc).isoformat()  # âœ… timezone-aware
                **{col: last_row[col] for col in required_columns},
                'news_sentiment': self.news_sentiment.get(symbol, {}).get('score', 0),
                'signal_count': len(self.pro_signals.get(symbol, [])),
                'target': target
            }
            
            file_path = f'training_data_{symbol}.csv'
            pd.DataFrame([new_data]).to_csv(
                file_path, 
                mode='a', 
                header=not os.path.exists(file_path), 
                index=False
            )
            
        except Exception as e:
            self.send_notification('error', f'ÙØ´Ù„ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {str(e)}')
            raise

    def send_notification(self, notification_type, data=None):
        """
        Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø¢Ù…Ù† Ù…Ø¹ Ø¶Ù…Ø§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
        Ø§Ù„Ù…ÙŠØ²Ø§Øª:
        1. ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† ØªÙˆÙƒÙ† ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        2. ÙŠØ­Ù…ÙŠ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        3. ÙŠØ³Ø¬Ù„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        4. Ù„Ø§ ÙŠØªÙˆÙ‚Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„
        """
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            if not hasattr(self, 'tg_bot') or not hasattr(self.tg_bot, 'token'):
                self._log_failure("Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¨ÙˆØª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…", notification_type)
                return False

            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±
            valid_types = {'start', 'shutdown', 'error', 'buy', 'sell', 'report', 'update', 'warning'}
            if notification_type not in valid_types:
                self._log_failure(f"Ù†ÙˆØ¹ Ø¥Ø´Ø¹Ø§Ø± ØºÙŠØ± ØµØ§Ù„Ø­: {notification_type}", notification_type)
                return False

            # 3. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            try:
                message = self._create_notification_message(notification_type, data or {})
                if not message or len(message) > 4096:
                    raise ValueError("Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©")
            except Exception as e:
                self._log_failure(f"ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {str(e)}", notification_type)
                return False

            # 4. ØªØ­Ø¯ÙŠØ¯ chat_id Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            chat_id = os.getenv(
                'TELEGRAM_DEV_CHAT_ID' if notification_type in {'error', 'warning'} 
                else 'TELEGRAM_GROUP_CHAT_ID'
            )
            if not chat_id:
                self._log_failure("Ù„Ù… ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ† chat_id", notification_type)
                return False

            # 5. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
            self.tg_bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode=telegram.constants.ParseMode.MARKDOWN,
            )
            return True

        except telegram.error.InvalidToken:
            self._log_failure("ØªÙˆÙƒÙ† ØªÙ„ÙŠØ¬Ø±Ø§Ù… ØºÙŠØ± ØµØ§Ù„Ø­", notification_type)
        except telegram.error.TelegramError as e:
            self._log_failure(f"Ø®Ø·Ø£ ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {str(e)}", notification_type)
        except Exception as e:
            self._log_failure(f"ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}", notification_type)
        
        return False

    def _log_error(self, error_msg, emergency_prefix=""):
        """
        Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© ØªØ³Ø¬Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ÙƒÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª
        - ØªØ¹Ù…Ù„ Ù…Ø¹ Ø£Ùˆ Ø¨Ø¯ÙˆÙ† logger
        - ØªÙƒØªØ¨ ÙÙŠ Ù…Ù„Ù Ø·ÙˆØ§Ø±Ø¦ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        - ØªØ¶ÙŠÙ Ø¨Ø§Ø¯Ø¦Ø© Ø·ÙˆØ§Ø±Ø¦ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
        """
        full_msg = f"{emergency_prefix}{error_msg}" if emergency_prefix else error_msg
        
        try:
            if hasattr(self, 'logger') and self.logger.handlers:
                self.logger.error(full_msg)
            else:
                # Ù†Ø¸Ø§Ù… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø§Ù„Ù…ØªØ¯Ø±Ø¬
                try:
                    with open('emergency_errors.log', 'a', encoding='utf-8') as f:
                        f.write(f"[{datetime.now()}] {full_msg}\n")
                except Exception as e:
                    print(f"[FALLBACK] {full_msg} | Exception: {str(e)}")
        except Exception as e:
            print(f"[CRITICAL] ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {str(e)} | Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: {error_msg}")

    def _safe_send_to_telegram(self, chat_id, message, notification_type, max_retries=3):
        """Ø¥Ø±Ø³Ø§Ù„ Ø¢Ù…Ù† Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¶Ù…Ø§Ù†Ø§Øª"""
        for attempt in range(max_retries):
            try:
                if not all([chat_id, message, notification_type]):
                    raise ValueError("Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ø±Ø³Ø§Ù„ ØºÙŠØ± ØµØ§Ù„Ø­Ø©")

                self.tg_bot.send_message(
                    chat_id=chat_id,
                    text=message,
                    parse_mode=ParseMode.MARKDOWN,
                    disable_web_page_preview=True
                )
                return True

            except telegram.error.RetryAfter as e:
                wait_time = e.retry_after + 2
                time.sleep(wait_time)
                continue

            except telegram.error.TelegramError as tg_error:
                error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {str(tg_error)}"
                self._log_error(error_msg)
                if attempt == max_retries - 1:
                    self._emergency_log_notification('telegram_failure', error_msg)
                time.sleep(2 ** attempt)
                continue

            except Exception as e:
                error_msg = f"ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {str(e)}"
                self._log_error(error_msg)
                if attempt == max_retries - 1:
                    self._emergency_log_notification('send_failure', error_msg)
                time.sleep(1)
                continue

        return False

    def _emergency_log_notification(self, error_type, error_details):
        """Ù†Ø¸Ø§Ù… Ø·ÙˆØ§Ø±Ø¦ Ù…ØªÙƒØ§Ù…Ù„"""
        try:
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'type': error_type,
                'details': error_details,
                'bot_status': {
                    'running': getattr(self, 'is_running', False),
                    'positions': len(getattr(self, 'current_positions', []))
                }
            }

            try:
                with open('notification_errors.jsonl', 'a', encoding='utf-8') as f:
                    f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
            except Exception:
                with open('notification_errors.log', 'a', encoding='utf-8') as f:
                    f.write(f"{log_entry['timestamp']} | {error_type} | {error_details}\n")

        except Exception as e:
            print(f"EMERGENCY: {error_type} - {error_details} | {str(e)}")

    def _create_notification_message(self, notification_type, data):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±"""
        messages = {
            'start': "âœ… **ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª Ø¨Ù†Ø¬Ø§Ø­**\n" + self._get_system_info(),
            'shutdown': f"ğŸ›‘ **ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨ÙˆØª**\nØ§Ù„Ø³Ø¨Ø¨: {data.get('reason', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}",
            'connection': f"ğŸŒ **Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„**: {data.get('status', 'Ø§Ù†Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„')}",
            'buy': (
                f"ğŸš€ **Ø´Ø±Ø§Ø¡ Ø¬Ø¯ÙŠØ¯**\n"
                f"ğŸª™ Ø§Ù„Ø¹Ù…Ù„Ø©: {data.get('symbol', 'N/A')}\n"
                f"ğŸ“Š Ø§Ù„ÙƒÙ…ÙŠØ©: {data.get('quantity', 'N/A')}\n"
                f"ğŸ’° Ø§Ù„Ø³Ø¹Ø±: {data.get('price', 'N/A')}\n"
                f"ğŸ’µ Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±: {data.get('investment', 'N/A')}"
            ),
            'sell': (
                f"ğŸ’° **Ø¥ØºÙ„Ø§Ù‚ ØµÙÙ‚Ø©**\n"
                f"ğŸª™ Ø§Ù„Ø¹Ù…Ù„Ø©: {data.get('symbol', 'N/A')}\n"
                f"ğŸ“Š Ø§Ù„ÙƒÙ…ÙŠØ©: {data.get('quantity', 'N/A')}\n"
                f"ğŸ’° Ø³Ø¹Ø± Ø§Ù„Ø¨ÙŠØ¹: {data.get('price', 'N/A')}\n"
                f"ğŸ“ˆ Ø§Ù„Ø±Ø¨Ø­: {data.get('profit', 'N/A')}%\n"
                f"â± Ø§Ù„Ù…Ø¯Ø©: {data.get('duration', 'N/A')}"
            ),
            'error': f"âŒ **Ø®Ø·Ø£**: {data if isinstance(data, str) else str(data)}",
            'report': (
                f"ğŸ“Š **ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡**\n"
                f"ğŸ“ˆ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: {data.get('active_signals', 0)}\n"
                f"ğŸ”® Ø§Ù„ØªÙˆÙ‚Ø¹: {data.get('prediction', 'N/A')}"
            )
        }
        
        return messages.get(notification_type, f"ğŸ”” Ø¥Ø´Ø¹Ø§Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {notification_type}")

    def _send_to_telegram(self, notification_type, message):
        """Ø¥Ø±Ø³Ø§Ù„ ÙØ¹Ù„ÙŠ Ø¹Ø¨Ø± Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…"""
        chat_id = os.getenv('TELEGRAM_PRIVATE_CHAT_ID' if notification_type in ['start', 'shutdown', 'error', 'connection'] else 'TELEGRAM_GROUP_CHAT_ID')
        self.tg_bot.send_message(
            chat_id=chat_id,
            text=message,
            parse_mode=ParseMode.MARKDOWN
        )

    def _safe_send_message(self, chat_id, message, retries=3):
        """Ø¥Ø±Ø³Ø§Ù„ Ø¢Ù…Ù† Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø©"""
        for attempt in range(retries):
            try:
                self.tg_bot.send_message(
                    chat_id=chat_id,
                    text=message,
                    parse_mode=ParseMode.MARKDOWN
                  
                )
                return
            except NetworkError:
                if attempt == retries - 1:
                    raise
                time.sleep(5)

    def run(self):
        """Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª"""
        try:
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©
            for symbol in self.symbols:
                if not self.validate_daily_data(symbol):
                    self.send_notification('error', f"Ø¨ÙŠØ§Ù†Ø§Øª {symbol} ØºÙŠØ± ØµØ§Ù„Ø­Ø©!")
            
            # 2. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø°ÙƒÙŠØ©
            self.adaptive_training_schedule()  # Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªÙƒÙŠÙÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            schedule.every(15).minutes.do(self.generate_performance_report)  # Ù…Ù† Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù‚Ø¯ÙŠÙ…
            schedule.every(1).hours.do(self.rotate_data_sources)  # Ù…Ù† Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù‚Ø¯ÙŠÙ…
            schedule.every().monday.at("03:00").do(self.analyze_market_timing)  # Ù…Ù† Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù‚Ø¯ÙŠÙ…
            
            self.start_bot()
            self.start_scheduler()  # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„

            # 3. Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            while self.is_running:
                try:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
                    if not self.check_internet_connection():
                        self.handle_connection_loss()
                        continue
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¹Ù…Ù„Ø© Ù…Ø¹ Ø¯Ù…Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                    for symbol in self.symbols:
                        # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¬Ø¯ÙŠØ¯
                        df = self.collect_market_data(symbol)
                        if df is None or df.empty:
                            continue
                        
                        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø«
                        df = self.calculate_technical_indicators(df)
                        
                        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                        input_data = self.prepare_input_data(df)
                        prediction = self.models[symbol].predict(input_data)
                        
                        # Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªÙƒÙŠÙÙŠØ©
                        if prediction == 1:
                            self.execute_trade(symbol)
                            
                    # Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ù…ÙØªÙˆØ­Ø© (Ø§Ù„Ù…Ø­Ø¯Ø«Ø©)
                    self.manage_all_positions()
                    
                    # ÙØ§ØµÙ„ Ø²Ù…Ù†ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ø¯ÙˆØ±Ø§Øª
                    time.sleep(60)

                except Exception as e:
                    self.logger.critical("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: %s", str(e), exc_info=True)
                    time.sleep(300)  # Ø§Ù†ØªØ¸Ø§Ø± Ø£Ø·ÙˆÙ„ Ø¹Ù†Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø­Ø±Ø¬Ø©

        except Exception as e:
            self.logger.error("Ø§Ù†Ù‡ÙŠØ§Ø± ÙÙŠ Ø¯Ø§Ù„Ø© run: %s", str(e), exc_info=True)
            self.shutdown_bot(reason=f"Ø®Ø·Ø£ Ø­Ø±Ø¬: {type(e).__name__}")
